{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"9Qp6j_DRGSdl"},"source":["## Estraçaõ e Preparação de dados"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import dask.dataframe as dd\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import ListedColormap\n","import matplotlib.cm as cm\n","import seaborn as sns\n","from Read_Scenarios import *\n","import os\n","\n","# ************************************************************************************************\n","#                                       OPÇÕES DE EJECUÇÃO\n","# ************************************************************************************************\n","\n","genscriptbool = False\n","extract_fromcsv = True\n","\n","# Analises\n","ConvergenceAnalise = True\n","LinhaAnalise = True\n","ReservaAnalise = True\n","IntercambiosAnalise = True\n","#------------------------------\n","linhascsv = False\n","reservacsv =False\n","# CorrelationAnalise = True\n","PlotGeralPotencia = True\n","MapasAnalise = True\n","ComputeDPI = True\n","resumoIndice = True\n","# Plots\n","Plot_Tensao_Geral = True  #PERMITE SALVAR OS DATAFRAMES DE df_Final_ger e df_Final_nt\n","plotDPI =  True\n","PlotDPICriticosPot = True\n","BP_Criticalbuses = True\n","PlotIntercambios = True\n","\n","# PlotAnaliseEstab = False"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# path_folder = 'D:/MPV_(FNS Lim)_RC/'\n","# ============================= CASOS 2022 ===========================================\n","# path_folder = 'D:/0 FERV/0 Dados PYTHON/Cenarios HPPA PRE-QUALI/MPV_(FNS Lim)_RC/'\n","\n","# path_folder = 'D:/0 FERV/0 Dados PYTHON/Cenarios HPPA PRE-QUALI/V1A1F2_REV2_091123/'\n","# path_folder = 'D:/0 FERV/0 Dados PYTHON/Cenarios HPPA PRE-QUALI/V2A2F2_REV4_081123/'\n","# path_folder = 'D:/0 FERV/0 Dados PYTHON/Cenarios HPPA PRE-QUALI/V3A3F2_REV2_091123/'\n","\n","# ============================= CASOS 2026 V2A2F_===========================================\n","# path_folder = 'D:/0 FERV/0 Dados PYTHON/CASOS 2026/V2A2F_/V2A2F2_RESP_FNS_lim_rev2_2026/'\n","# path_folder = 'D:/0 FERV/0 Dados PYTHON/CASOS 2026/V2A2F_/V2A2F3_RESP_FNS_lim_rev1_2026/'\n","# path_folder = 'D:/0 FERV/0 Dados PYTHON/CASOS 2026/V2A2F_/V2A2F4_RESP_FNS_lim_rev1_2026/'\n","# path_folder = 'D:/0 FERV/0 Dados PYTHON/CASOS 2026/V2A2F_/V2A2F5_RESP_FNS_lim_rev1_2026/'\n","# ============================= CASOS 2026 V1A1F_===========================================\n","# path_folder = 'D:/0 FERV/0 Dados PYTHON/CASOS 2026/V1A1F_/V1A1F2_RESP_FNS_lim_rev1_2026/'\n","# path_folder = 'D:/0 FERV/0 Dados PYTHON/CASOS 2026/V1A1F_/V1A1F3_RESP_FNS_lim_rev1_2026/'\n","# path_folder = 'D:/0 FERV/0 Dados PYTHON/CASOS 2026/V1A1F_/V1A1F4_RESP_FNS_lim_rev1_2026/'\n","path_folder = 'D:/0 FERV/0 Dados PYTHON/CASOS 2026/V1A1F_/V1A1F5_RESP_FNS_lim_rev1_2026/'\n","\n","if extract_fromcsv:\n","    pathcsv1 = path_folder + 'ProcessedDataBase.csv'\n","    pathcsv2 = None\n","else:\n","    pathcsv1 = None\n","    pathcsv2 = path_folder + 'ProcessedDataBase.csv'\n","\n","cases = Read_Scenarios(path_folder, RST=False, pathcsv = pathcsv1, genscript=genscriptbool)\n","cenario = cases.cenario"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if ConvergenceAnalise:\n","    OPFs_concatenados = cases.OPF\n","    OPF_NC = OPFs_concatenados[(OPFs_concatenados['Valor4'] == 'F')].copy()\n","    PWF_NC = OPFs_concatenados[(OPFs_concatenados['Valor5'] == 'F')].copy()\n","    PWF_CV = OPFs_concatenados[(OPFs_concatenados['Valor5'] == 'T')].copy()\n","    print('====================================================================')\n","    print('Numero de casos não Convergidos no PWF: ' + str(len(PWF_NC)) + '=> ' +  str(round(len(PWF_NC)/1344*100,2)))\n","    print('Numero de casos não Convergidos no OPF: ' + str(len(OPF_NC)) + '=> ' + str(round(len(OPF_NC)/1344*100,2)))\n","    print('====================================================================')\n","    ## ====================================================================================================================================================================================\n","    OPF_NC[['Dia','Hora']].to_csv(cenario+'/OPF_NC.csv', index=None)\n","    PWF_NC[['Dia','Hora']].to_csv(cenario+'/PWF_NC.csv', index=None)\n","    print('Os pontos de operação não convergidos no PWF são:')\n","    bool_PWF_NConv = PWF_NC[['Dia', 'Hora']].apply(tuple, axis=1)\n","    print(bool_PWF_NConv.values)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from ProcessData import *\n","\n","busdata = True\n","## ***************** (Este código adiciona as barras pertencentes a cada estado e agrupa por região e barra) *****************\n","print('******************** PREPARAÇÃO DE DADOS ********************')\n","processdata = ProcessData(cases.DfAnalysis, pathcsv2, extract_fromcsv, busdata)\n","df_Final_ger = processdata.df_Final_ger\n","df_Final_nt = processdata.df_Final_nt\n","dff_Ger_map = processdata.dff_Ger_map\n","dff_Ger_map.loc[dff_Ger_map['Gen_Type']=='UNE','Gen_Type'] = 'UTE' # cambia de designación de usinas nucleares a termicas para ser plotadas en el mapa\n","dff_NT_map = processdata.dff_NT_map\n","\n","DF_REGIONAL_GER = processdata.DF_REGIONAL_GER\n","DF_REGIONAL_GER['QG/QL'] = DF_REGIONAL_GER['QG_MVAR']/DF_REGIONAL_GER['QL_MVAR']\n","DF_REGIONAL_GER['PG/PL'] = DF_REGIONAL_GER['PG_MW']/DF_REGIONAL_GER['PL_MW']\n","DF_REGIONAL_GER['PG_FERV'] =  (DF_REGIONAL_GER['PG_EOL'] + DF_REGIONAL_GER['PG_SOL'])/DF_REGIONAL_GER['PL_MW']\n","DF_REGIONAL_GER['ReservaINDshunt'] = DF_REGIONAL_GER['SHUNT_INST_IND'] - DF_REGIONAL_GER['Shunt_Ind']\n","DF_REGIONAL_GER['ReservaCAPshunt'] = DF_REGIONAL_GER['SHUNT_INST_CAP'] - DF_REGIONAL_GER['Shunt_Cap']\n","\n","DF_REGIONAL_GER[['PG_MW', 'QG_MVAR', 'PL_MW', 'QL_MVAR','Shunt_Ind', 'Shunt_Cap','SHUNT_INST_IND', 'SHUNT_INST_CAP', 'ReservaIND', 'ReservaCAP',\n","                'PG_UHE', 'PG_UTE', 'PG_EOL', 'PG_SOL', 'PG_BIO', 'PG_Dist', 'QG/QL', 'PG/PL', 'PG_FERV', 'ReservaINDshunt', 'ReservaCAPshunt']].to_csv(cenario+'/DF_POT_Reg.csv')\n","\n","DF_REGIONAL_PQ = processdata.DF_REGIONAL_PQ\n","\n","# barras  = ['MSULD3-EOL22', 'CLEMNTEOL-66', 'CLEMNTEOL-60', 'MSULD1-EOL27', 'MSULD2-EOL27', 'MSULD4-EOL08'] #em algun momento asignar EOL no Tipo de usina nessas barras que não esta asignando automaticamente"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## ***************** (Este código obtem as informações das linhas AC e DC e reserva por maquina) *****************\n","# cases.generatescript()\n","if linhascsv | reservacsv:\n","        PWF16_concatenados = dd.read_csv(path_folder + '/LinhasInfo.csv', sep=',').compute()\n","        PWF16_concatenados['Dia'] = PWF16_concatenados['Dia'].astype(str)\n","        PWF16_concatenados['Dia'] = PWF16_concatenados['Dia'].str.zfill(2)\n","\n","        if IntercambiosAnalise:\n","                cases.get_Intercambios(df = PWF16_concatenados)\n","        if reservacsv:\n","                SGN01_concatenados = dd.read_csv(path_folder + '/ReservaInfo.csv', sep=',').compute()\n","                SGN01_concatenados['Dia'] = SGN01_concatenados['Dia'].astype(str)\n","                SGN01_concatenados['Dia'] = SGN01_concatenados['Dia'].str.zfill(2)\n","\n","elif (LinhaAnalise == True )|(ReservaAnalise == True):\n","    cases.get_Networkinfo(linhas = LinhaAnalise, Reserva = ReservaAnalise, Intercambios = IntercambiosAnalise)\n","    if LinhaAnalise:\n","        PWF16_concatenados = cases.linesInfo\n","        if IntercambiosAnalise:\n","            DCLinks_concatenados = cases.HVDCInfo\n","            DF_Intercambios = cases.DF_Intercambios\n","    if ReservaAnalise:\n","        SGN01_concatenados = cases.ReserveInfo\n"]},{"cell_type":"markdown","metadata":{},"source":["# Definição Funcões Gerais"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Definição de Funções Gerais =========================================================================================\n","\n","plt.rcParams[\"font.family\"] = \"Times New Roman\"\n","paletadcolor = sns.color_palette()\n","\n","def plot_boxplot(data, labels, title, xlabel, ylabel, limites=None, vert = True, rotation = 0, text = True, nbarra = None):\n","    \n","    markerfacecolor = dict(markerfacecolor='gray', marker='o')  # El diccionario que define el color y marcador\n","    fig1, axs = plt.subplots(figsize=(25, 20))\n","    if vert:\n","        axs.boxplot(data, flierprops=markerfacecolor)\n","        \n","        # axs.spines['top'].set_visible(False)\n","        # axs.spines['right'].set_visible(False)\n","        # axs.spines['left'].set_visible(False)\n","        # axs.spines['bottom'].set_color('#DDDDDD')\n","        axs.tick_params(bottom=False, left=False)\n","        axs.set_axisbelow(True)\n","        \n","\n","        # Agregar etiquetas de texto con el número de muestras\n","        if text:\n","            for i, data_item in enumerate(data):\n","                num_muestras = len(data_item)\n","                if num_muestras > 0: \n","\n","                    try:\n","                        axs.text(i+1, np.max(data_item)+0.005, f'Buses = {nbarra[i].size} ', ha='center', va='bottom',size=18)\n","                        axs.text(i+1, np.median(data_item), f' {np.mean(data_item):.3f} ', ha='center', va='bottom',size=15)\n","                        axs.text(i+1.4, np.quantile(data_item, q=0.25), f' {np.quantile(data_item, q=0.25):.3f} ', ha='center', va='bottom',size=15)\n","                        axs.text(i+1.4, np.quantile(data_item, q=0.75), f' {np.quantile(data_item, q=0.75):.3f} ', ha='center', va='bottom',size=15)\n","                        \n","                    except:\n","                        axs.text(i+1.4, np.mean(data_item), f'{num_muestras}', ha='center', va='bottom',size=25)\n","        \n","        if limites != None:\n","            axs.set_ylim(limites)\n","            # axs.set_yticks(np.linspace(limites[0],limites[1],12))\n","        plt.xticks(range(1, len(labels)+1), labels, fontsize=15)\n","\n","    else:\n","        axs.boxplot(data, vert=False, flierprops=markerfacecolor)\n","        if limites != None:\n","            axs.set_xlim(limites)\n","            axs.set_xticks(np.linspace(limites[0],limites[1],20))\n","        if text:\n","                axs.text(np.median(data), 1.1 , f' {np.mean(data):.3f} ', ha='center', va='bottom',size=18)\n","\n","    plt.xlabel(xlabel, fontsize=22)\n","    plt.ylabel(ylabel, fontsize=22)\n","    plt.title(title, fontsize=25)\n","    plt.xticks(fontsize=20, rotation = rotation)\n","    plt.yticks(fontsize=25)\n","    plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.6)\n","    axs.xaxis.grid(False)\n","    nome = cenario + '/BoxPlot/' + title + '.png'\n","    plt.savefig(nome, bbox_inches = 'tight')\n","    # nome = cenario + '/BoxPlot/' + title + '.svg'\n","    # plt.savefig(nome)\n","    plt.show()\n","\n","def plot_Potencia(df_data, eje_y, title, limites=None):\n","    \n","    fig, axs = plt.subplots(nrows=1, figsize=(20, 10), sharex=False)\n","\n","    axs.plot(df_data.values, color=sns.color_palette(\"Paired\")[1])\n","        \n","    # axs.legend(loc='best', fontsize=12)\n","    # Calculate the number of data points in a day (assuming each day has 48 data points)\n","    data_points_per_day = 48\n","    # Calculate the number of days based on the length of the data\n","    num_days = len(df_data) // data_points_per_day\n","    # Set x-axis ticks and labels for each day\n","    axs.set_xticks([i * data_points_per_day for i in range(num_days)])\n","    axs.set_xticklabels([f'Day {i+1}' for i in range(num_days)], fontsize=18, rotation=45, ha='right')\n","    axs.tick_params(axis='y', labelsize=18)\n","    axs.set_xlabel('Days', fontsize=18)\n","    axs.set_ylabel(eje_y, fontsize=18)\n","    axs.set_title(title, fontsize=20)\n","    if limites != None:\n","        axs.set_xlim(limites)\n","    axs.grid()\n","    plt.tight_layout()\n","    nome = cenario + '/Potencia/' + title + '.png'\n","    plt.savefig(nome, bbox_inches = 'tight')\n","    plt.show()\n","\n","def plot_reserva_reg (df_data, eje_y, name, title, INDICE, xlimites=None,ylimites=None, display_ = True, order = False):\n","\n","    if display_:\n","        display(df_data[df_data[INDICE]==df_data[INDICE].max()].T)\n","    \n","    fig, axs = plt.subplots(nrows=1, figsize=(20, 10), sharex=False)\n","    colores = [sns.color_palette(\"Paired\")[1], sns.color_palette(\"Paired\")[3], sns.color_palette(\"Paired\")[4],sns.color_palette(\"Paired\")[7],sns.color_palette(\"Paired\")[9]]\n","    region_map = {'Nordeste':'Northeast', 'Norte':'North', 'Sudeste-Centro-Oeste':'SE-CW', 'Sul':'South','AC-RO':'AC-RO'}\n","    for idx, regiao in enumerate(['Norte','Nordeste','Sudeste-Centro-Oeste', 'Sul', 'AC-RO']):\n","        \n","        if order:\n","            data = df_data.loc[:, :, regiao].sort_values(INDICE, ascending=False)[INDICE]\n","        else:\n","            data = df_data.loc[:, :, regiao][INDICE]\n","        \n","        axs.plot(data.values, color=colores[idx], label=region_map[regiao], lw=2, linestyle='-')\n","        \n","    axs.legend(loc='upper right', fontsize=18)\n","    axs.tick_params(axis='y', labelsize=24)\n","    axs.tick_params(axis='x', labelsize=24)\n","    axs.set_xlabel('Pontos de Operação', fontsize=23)\n","    axs.set_ylabel(eje_y, fontsize=22)\n","    axs.set_title(title, fontsize=22)\n","    if xlimites != None:\n","        axs.set_xlim(xlimites)\n","    if ylimites != None:\n","        axs.set_ylim(ylimites)\n","    axs.grid(True, linestyle='-', linewidth=1.2, alpha=0.4)\n","    plt.tight_layout()\n","    nome = cenario + '/Potencia/' + name + '.png'\n","    plt.savefig(nome)\n","    plt.show()\n","\n","def plot_Intercambio (df_AC, df_DC , eje_y, title, COL_AC, COL_DC, Ylimites=None, Xlimites=  None):\n","\n","    fig, axs = plt.subplots(nrows=1, figsize=(16, 7))\n","    colores1 = [paletadcolor[0], paletadcolor[1], paletadcolor[2],paletadcolor[3],paletadcolor[4], paletadcolor[5]]\n","    colores2 = [paletadcolor[5], paletadcolor[4], paletadcolor[3],paletadcolor[2],paletadcolor[1], paletadcolor[0]]\n","\n","    # DF_REGIONAL_GER.loc[:,:,'Nordeste']['PG_EOL'].plot(figsize=(10, 6),lw=1.5, color = paletadcolor[5])\n","\n","    for idx, fluxo in enumerate(COL_AC): \n","        data_ = df_AC.loc[fluxo]['MW:From-To']\n","        axs.plot(data_.values, color=colores1[idx], label= fluxo.replace('_',' '), lw=1.4, linestyle='-')\n","    for idx, fluxo in enumerate(COL_DC): \n","        data_ = df_DC.loc[fluxo][' P(MW)']\n","        axs.plot(data_.values, color=colores2[idx+1], label= fluxo.replace('_',' '), lw=2.2, linestyle='-')\n","\n","    axs.xaxis.set_major_locator(plt.MaxNLocator(12))\n","    axs.legend(loc='best', fontsize=14)\n","    axs.tick_params(axis='y', labelsize=15)\n","    axs.tick_params(axis='x', labelsize=15)\n","    axs.set_xlabel('Semihoras', fontsize=15)\n","    axs.set_ylabel(eje_y, fontsize=15)\n","    axs.set_title(title, fontsize=20)\n","    if Ylimites != None:\n","        axs.set_ylim(Ylimites)\n","    if Xlimites != None:\n","        axs.set_xlim(Xlimites)\n","    axs.grid(True, linestyle='--', linewidth=1, alpha=0.2)\n","    plt.tight_layout()\n","    nome = cenario + '/Intercambios/' + title + '.png'\n","    plt.savefig(nome)\n","    plt.show()\n","\n","def plot_indice_0 (df_data, eje_y, name, title, INDICE, xlimites=None,ylimites=None, order = False, ax=None):\n","    \n","    if ax is None:\n","        fig, axs = plt.subplots(nrows=1, figsize=(15, 6), sharex=False)\n","    else:\n","        axs = ax\n","\n","    colores = [sns.color_palette(\"Paired\")[5], sns.color_palette(\"Paired\")[1], sns.color_palette(\"Paired\")[3]]\n","    if order:\n","        data = df_data.sort_values(INDICE, ascending=False)[INDICE]\n","        data_points_per_day = 10\n","        num_days = (len(df_data))*data_points_per_day / 100\n","        axs.set_xticks([round(i * num_days) for i in range(data_points_per_day+1)])\n","        axs.set_xticklabels([f'{i*10}' for i in range(data_points_per_day+1)], fontsize=12, rotation=0, ha='center')\n","        axs.set_xlabel('Percentage of half hours in a month (%)', fontsize=23)\n","    else:\n","        data = df_data[INDICE]\n","        axs.set_xlabel('Operating Points', fontsize=23)\n","    \n","    area_trapezoidal = np.trapz(data.values)/len(data)\n","    media = np.mean(data.values)\n","    axs.plot(data.values, color=colores[1], label='Todos os Cenarios', lw=2, linestyle='-')\n","        \n","    axs.legend(loc='upper right', fontsize=18)\n","    axs.tick_params(axis='y', labelsize=24)\n","    axs.tick_params(axis='x', labelsize=24)\n","    axs.set_ylabel(eje_y, fontsize=22)\n","    axs.set_title(f'{title} normalized area/mean: {area_trapezoidal, media}', fontsize=15)\n","    if xlimites is not None:\n","        axs.set_xlim(xlimites)\n","    if ylimites is not None:\n","        axs.set_ylim(ylimites)\n","    axs.grid(True, linestyle='-', linewidth=1.2, alpha=0.4)\n","    plt.tight_layout()\n","    if ax is None:\n","        nome = cenario + '/Indice/' + name + '.png'\n","        plt.savefig(nome, bbox_inches = 'tight')\n","        plt.show()\n","    return area_trapezoidal\n"]},{"cell_type":"markdown","metadata":{},"source":["# Intercambios AC e DC"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# processdata.Df_VF_SF[(processdata.Df_VF_SF['Dia'] == '01') & (processdata.Df_VF_SF['Hora'] == '00-00')][['BUS_ID','BUS_NAME','VBASEKV','REG', 'U_FED']].to_csv('BarrasGeoreferenciadas.csv',index=None)\n","\n","def addUF_linha(from_bus, to_bus, bus_info_map, vbasekv_map):\n","\n","    reg1 = bus_info_map.get(from_bus, np.nan)\n","    Vbase1 = vbasekv_map.get(from_bus, np.nan)\n","    reg2 = bus_info_map.get(to_bus, np.nan)\n","\n","    if reg1 == reg2 and reg1 is not np.nan:\n","        return reg1, Vbase1\n","    else:\n","        return np.nan, np.nan\n","\n","def Main_linha_addREG(PWF16_concatenados):\n","\n","    Df_VF_SF = processdata.Df_VF_SF\n","    InfoBarras = Df_VF_SF[(Df_VF_SF['Dia']=='01') & (Df_VF_SF['Hora']=='00-00')][['BUS_ID','BUS_NAME', 'ARE','VBASEKV','REG', 'U_FED', 'Gen_Type','Latitude', 'Longitude']]\n","    PWF16_concatenados_d1 = PWF16_concatenados[(PWF16_concatenados['Dia'] == '01') & (PWF16_concatenados['Hora'] == '00-00')].groupby(by=['From#','To#']).first().reset_index().copy()\n","\n","    # Create a dictionary to map 'BUS_ID' to 'REG' and 'VBASEKV'\n","    bus_info_map = dict(zip(InfoBarras['BUS_ID'], InfoBarras['REG']))\n","    vbasekv_map = dict(zip(InfoBarras['BUS_ID'], InfoBarras['VBASEKV']))\n","\n","    # Use the apply function to create 'REG' and 'VBASEKV' columns in PWF16_concatenados_d1\n","    PWF16_concatenados_d1['REG'], PWF16_concatenados_d1['VBASEKV'] = zip(*PWF16_concatenados_d1.apply(lambda row: addUF_linha(row['From#'], row['To#'], bus_info_map, vbasekv_map), axis=1))\n","\n","    PWF16_concatenados_R = PWF16_concatenados.merge(PWF16_concatenados_d1[['From#','To#','REG','VBASEKV']], on=['From#','To#'], how='left')\n","    PWF16_Filt_linhas = PWF16_concatenados_R[(PWF16_concatenados_R['Type'] == ' TL') & ~(PWF16_concatenados_R['REG'].isna())]\n","    PWF16_Filt_TRAFO = PWF16_concatenados_R[(PWF16_concatenados_R['Type'] == ' TRAFO') & ~(PWF16_concatenados_R['REG'].isna())]\n","\n","    return PWF16_Filt_linhas, PWF16_Filt_TRAFO\n","\n","if LinhaAnalise:\n","\n","    PWF16_Filt_linhas, PWF16_Filt_TRAFO = Main_linha_addREG(PWF16_concatenados)\n","    PWF16_Filt_linhas[['From#','To#','From Name','To Name','% L1', 'L1(MVA)', 'Mvar:Losses','Dia', 'Hora','REG', 'VBASEKV','MVA', 'MW:From-To', 'MW:To-From','Power Factor:From-To','Power Factor:To-From']].to_csv(cenario+'/Linhas.csv', index=None)\n","    PWF16_Filt_TRAFO[['From#','To#','From Name','To Name','% L1', 'L1(MVA)', 'Mvar:Losses','Dia', 'Hora','REG', 'VBASEKV','MVA', 'MW:From-To', 'MW:To-From','Power Factor:From-To','Power Factor:To-From']].to_csv(cenario+'/Trafo.csv', index=None)\n","    PWF16_Filt_grouped = PWF16_Filt_linhas[PWF16_Filt_linhas['VBASEKV'].isin([230, 345, 440, 500, 525, 765])].groupby(by = ['Dia','Hora','REG']).agg({'% L1':'mean', 'Mvar:Losses':'sum'}) \n","\n","    if IntercambiosAnalise:\n","        ## ========================================== ELOS SEPARADOS POR BIPOLOS:\n","        # pole_mapping = {1: 'Bipolo1', 2: 'Bipolo1', 3: 'Bipolo2', 4: 'Bipolo2'}\n","        # dfelo1 = DCLinks_concatenados[DCLinks_concatenados['Bus #'] == 85].groupby(by=['Dia', 'Hora', ' Pole #']).agg({' P(MW)': sum, ' Q(Mvar)': sum})\n","        # dfelo1['Nome Elo'] = 'Elo_FOZ-IBIUNA'\n","        # dfelo1['Bipole'] = dfelo1.index.get_level_values(' Pole #').map(pole_mapping)\n","        # dfelo2 = DCLinks_concatenados[DCLinks_concatenados['Bus #'] == 7055].groupby(by=['Dia', 'Hora', ' Pole #']).agg({' P(MW)': sum, ' Q(Mvar)': sum})\n","        # dfelo2['Nome Elo'] = 'Elo_PVEL-ARARQ'\n","        # dfelo2['Bipole'] = dfelo2.index.get_level_values(' Pole #').map(pole_mapping)\n","        # dfelo3 = DCLinks_concatenados[DCLinks_concatenados['Bus #'] == 7059].groupby(by=['Dia', 'Hora', ' Pole #']).agg({' P(MW)': sum, ' Q(Mvar)': sum})\n","        # dfelo3['Nome Elo'] = 'Elo_CPVBTB-PVEL'\n","        # dfelo3['Bipole'] = dfelo3.index.get_level_values(' Pole #').map(pole_mapping)\n","        # dfelo4 = DCLinks_concatenados[(DCLinks_concatenados['Bus #'] == 8100)].groupby(by=['Dia', 'Hora', ' Pole #']).agg({' P(MW)': sum, ' Q(Mvar)': sum})\n","        # dfelo4['Nome Elo'] = 'Elo_XINGU-SE'\n","        # dfelo4['Bipole'] = dfelo4.index.get_level_values(' Pole #').map(pole_mapping)\n","        # dfelo1.reset_index().groupby(['Dia', 'Hora', 'Bipole']).agg({' P(MW)': sum, 'Nome Elo': 'first'}).to_csv('HVDC_FOZ_IBIUNA.csv')\n","        # dfelo2.reset_index().groupby(['Dia', 'Hora', 'Bipole']).agg({' P(MW)': sum, 'Nome Elo': 'first'}).to_csv('HVDC_PVEL-ARARQ.csv')\n","\n","        ## ========================================== ELOS HVDC SEM SEPARAÇÃO POR POLOS:\n","\n","        dfelo1 = DCLinks_concatenados[DCLinks_concatenados['Bus #'] == 85].groupby(by=['Dia', 'Hora']).agg({' P(MW)': 'sum', ' Q(Mvar)': 'sum'})\n","        dfelo1['Nome Elo'] = 'Elo_FOZ-IBIUNA'\n","        dfelo2 = DCLinks_concatenados[DCLinks_concatenados['Bus #'] == 7055].groupby(by=['Dia', 'Hora']).agg({' P(MW)': 'sum', ' Q(Mvar)': 'sum'})\n","        dfelo2['Nome Elo'] = 'Elo_PVEL-ARARQ'\n","        dfelo3 = DCLinks_concatenados[DCLinks_concatenados['Bus #'] == 7059].groupby(by=['Dia', 'Hora']).agg({' P(MW)': 'sum', ' Q(Mvar)': 'sum'})\n","        dfelo3['Nome Elo'] = 'Elo_CPVBTB-PVEL'\n","        dfelo4 = DCLinks_concatenados[(DCLinks_concatenados['Bus #'] == 8100)].groupby(by=['Dia', 'Hora']).agg({' P(MW)': 'sum', ' Q(Mvar)': 'sum'})\n","        dfelo4['Nome Elo'] = 'Elo_XINGU-SE'\n","        dfelo4 = DCLinks_concatenados[(DCLinks_concatenados['Bus #'] == 8100) & (DCLinks_concatenados[' Pole #'].isin([1,2]))].groupby(by=['Dia', 'Hora']).agg({' P(MW)': 'sum', ' Q(Mvar)': 'sum'})\n","        # dfelo4['Nome Elo'] = 'Elo_XINGU-ESTREI'\n","        # dfelo5 = DCLinks_concatenados[(DCLinks_concatenados['Bus #'] == 8100) & (DCLinks_concatenados[' Pole #'].isin([3,4]))].groupby(by=['Dia', 'Hora']).agg({' P(MW)': 'sum', ' Q(Mvar)': 'sum'})\n","        # dfelo5['Nome Elo'] = 'Elo_XINGU-T.RIO'\n","        # Merge all dataframes\n","        # df_HVDC = pd.concat([dfelo1, dfelo2, dfelo3, dfelo4, dfelo5], axis=0, keys=['Elo_FOZ-IBIUNA', 'Elo_PVEL-ARARQ', 'Elo_CPVBTB-PVEL' ,'Elo_XINGU-ESTREI', 'Elo_XINGU-T.RIO'])\n","        df_HVDC = pd.concat([dfelo1, dfelo2, dfelo3, dfelo4], axis=0, keys=['Elo_FOZ-IBIUNA', 'Elo_PVEL-ARARQ', 'Elo_CPVBTB-PVEL' ,'Elo_XINGU-SE'])\n","        df_HVDC.to_csv(cenario+'/DF_HVDC.csv')\n","\n","        if PlotIntercambios == True:\n","            plot_Intercambio (DF_Intercambios, df_HVDC , '(MW)', 'Exportação (N-S, NE-SE) e  Elo Xingu-SE', ['Fluxo_N-S', 'Fluxo_NE-SE'], ['Elo_XINGU-SE'], )\n","            plot_Intercambio (DF_Intercambios, df_HVDC , '(MW)', 'Exportação N-S e  Elo Xingu-SE', ['Fluxo_N-S'], ['Elo_XINGU-SE'], )\n","            plot_Intercambio (DF_Intercambios, df_HVDC , '(MW)', 'Comparativo Exportação NE-N e Elo Xingu-SE', ['Fluxo_NE-N'], ['Elo_XINGU-SE'], Xlimites=None)\n","            plot_Intercambio (DF_Intercambios, df_HVDC , '(MW)', 'Comparativo Exportação NE-SE e Elo FOZ-IBIUNA', ['Fluxo_NE-SE'], ['Elo_FOZ-IBIUNA'], Xlimites=None)\n","            plot_Intercambio (DF_Intercambios, df_HVDC , '(MW)', 'Comparativo Exportação SUL-SECO e Elo FOZ-IBIUNA', ['Fluxo_SUL-SECO'], ['Elo_FOZ-IBIUNA'], Xlimites=None)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Reserva Regional"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if ReservaAnalise == True:\n","    if (SGN01_concatenados.empty == False):\n","\n","        df_Final_ger_mod = df_Final_ger[(df_Final_ger['Dia'] == '01') & (df_Final_ger['Hora'] == '00-00')][['BUS_ID', 'Gen_Type', 'U_FED', 'REG']]\n","        SGN01_concatenados.rename(columns={'Bus':'BUS_ID', }, inplace=True)\n","        Df_Reserva = SGN01_concatenados.merge(df_Final_ger_mod, how = 'left', on='BUS_ID')\n","\n","        REG_groupReserve = Df_Reserva.groupby(by = ['Dia','Hora', 'REG']).agg({' Reserve': sum})\n","        GroupReserve = Df_Reserva.groupby(by = ['Dia','Hora']).agg({' Reserve': sum})\n","        GroupReserve[' Reserve'].to_csv(cenario + '/Reserva_MW_PO.csv', header=True, index=True)\n","        REG_groupReserve[' Reserve'].to_csv(cenario + '/Reserva_MW_PO_REG.csv', header=True, index=True)\n","\n","        plot_Potencia(GroupReserve[' Reserve'], '(MW)', 'RESERVA (MW) - SIN', limites=None)\n","        plot_reserva_reg (REG_groupReserve, '(MW)', 'Reserva por Região', 'RESERVA POR REGIÃO', ' Reserve', xlimites=None,ylimites=None, display_ = False, order = False)\n","\n","# =====================================ESSE DATAFRAME É SÓ DA RESERVA DAS MAQUINAS COM MODELO DO GERADOR PARA O CONTROLE DE FREQ\n","# ===========================================================================================================================\n","\n","    dff_reserva = Df_Reserva.merge(df_Final_ger[['BUS_ID','Dia', 'Hora', 'QMX_MVAR', 'QMN_MVAR', 'Ger_Units','QG_MVAR']], on=['BUS_ID','Dia', 'Hora'], how='left')\n","        # Calculate 'Qmin' and 'Qmax' using vectorized operations\n","    dff_reserva['Qmin'] = (dff_reserva['QMN_MVAR'] / dff_reserva['Ger_Units']) * dff_reserva[' Units']\n","    dff_reserva['Qmax'] = (dff_reserva['QMX_MVAR'] / dff_reserva['Ger_Units']) * dff_reserva[' Units']\n","    # Use numpy's where function for conditional assignment in a vectorized way\n","    dff_reserva['ReservaIND'] = np.where(dff_reserva['QG_MVAR'] < 0, dff_reserva['Qmin'] - dff_reserva['QG_MVAR'], dff_reserva['Qmin'])\n","    dff_reserva['ReservaCAP'] = np.where(dff_reserva['QG_MVAR'] > 0, dff_reserva['Qmax'] - dff_reserva['QG_MVAR'], dff_reserva['Qmax'])\n","# ============================================================================================================================\n","\n","    dffreservaPO = df_Final_ger.groupby(['Dia', 'Hora']).agg({'QG_MVAR': sum, 'ReservaIND':sum, 'ReservaCAP':sum})\n","    dffreservaPO_REG = df_Final_ger.groupby(['Dia', 'Hora', 'REG']).agg({'QG_MVAR': sum, 'ReservaIND':sum, 'ReservaCAP':sum})\n","    # Salvando dataframe de reserva mvar ============================================\n","    dffreservaPO.to_csv(cenario + '/ReservaMVAR_PO.csv', header=True, index=True)\n","    dffreservaPO_REG.to_csv(cenario + '/ReservaMVAR_PO_REG.csv', header=True, index=True)\n","\n","#=============================================================================================================================\n","#                                                                   PLOTS RESERVA MVAR\n","#=============================================================================================================================\n","\n","    plot_reserva_reg (dffreservaPO_REG, '(MVAR)', 'Reserva Capacitiva por Região MVAR', 'RESERVA CAPACITIVA POR REGIÃO MVAR', 'ReservaCAP', xlimites=None,ylimites=None, display_ = False, order = False)\n","    plot_reserva_reg (dffreservaPO_REG, '(MVAR)', 'Reserva Indutiva por Região MVAR', 'RESERVA INDUTIVA POR REGIÃO MVAR', 'ReservaIND', xlimites=None,ylimites=None, display_ = False, order = False)\n","\n","    fig, ax = plt.subplots(figsize=(20,10))\n","    dffreservaPO['ReservaCAP'].plot(figsize=(20,10), grid=True, title='RESERVA CAPACITIVA (Mvar)',legend='RESERVA')\n","    ax.tick_params(axis='x', labelsize=15)\n","    ax.tick_params(axis='y', labelsize=15)\n","    ax.set_xlabel('PO',fontsize = 15)\n","    ax.set_ylabel('(MVAR)',fontsize = 15)\n","    ax.set_title('RESERVA CAPACITIVA (Mvar)', fontsize = 20)\n","    ax.legend(fontsize = 15)\n","    nome = cenario + '/Potencia/Reserva_cap_mvar.png'\n","    plt.savefig(nome, bbox_inches = 'tight')\n","\n","    fig, ax = plt.subplots(figsize=(20,10))\n","    dffreservaPO['ReservaIND'].plot(figsize=(20,10), grid=True, title='RESERVA INDUTIVA (Mvar)',legend='RESERVA')\n","    ax.tick_params(axis='x', labelsize=15)\n","    ax.tick_params(axis='y', labelsize=15)\n","    ax.set_xlabel('PO',fontsize = 15)\n","    ax.set_ylabel('(MVAR)',fontsize = 15)\n","    ax.set_title('RESERVA INDUTIVA (Mvar)', fontsize = 20)\n","    ax.legend(fontsize = 15)\n","    nome = cenario + '/Potencia/Reserva_ind_mvar.png'\n","    plt.savefig(nome, bbox_inches = 'tight')"]},{"cell_type":"markdown","metadata":{},"source":["# Potencia e Tensão - Geral"]},{"cell_type":"markdown","metadata":{},"source":["### a) Potencia Ativa e Reativa"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["regioes = DF_REGIONAL_GER.reset_index()['REG'].unique()\n","df_pg = DF_REGIONAL_GER.reset_index(level=['Dia','Hora', 'REG'])[['PG_MW','PL_MW','PG_EOL','PG_SOL', 'Dia', 'Hora', 'MODV_PU', 'QG_MVAR']]\n","df_pg['PG_FERV'] =  (df_pg['PG_EOL'] + df_pg['PG_SOL'])/df_pg['PL_MW']\n","df_grouped = df_pg.groupby(by = ['Dia', 'Hora'])[['PG_FERV', 'MODV_PU', 'QG_MVAR','PG_MW', 'PL_MW' ]].sum()\n"," # Salvando dataframe de POTENCIA MW, RESERVA E MVAR===========================================\n","df_grouped['PG_MW'].to_csv(cenario + '/MW_PO.csv', header=True, index=True)\n","df_grouped['QG_MVAR'].to_csv(cenario + '/MVAR_PO.csv', header=True, index=True)\n","# =============================================================================================\n","if PlotGeralPotencia:\n","    plot_Potencia(df_grouped['QG_MVAR'], '(MVAR)', 'POTENCIA REATIVA GERADA (MVAR) - SIN', limites=None)\n","    plot_Potencia(df_grouped['PG_MW'], '(MW)', 'POTENCIA ATIVA GERADA (MW) - SIN', limites=None)\n","    typeGenDic = {'QG_UHE':'Num_Usinas_UHE', 'QG_UTE':'Num_Usinas_UTE', 'QG_EOL':'Num_Usinas_EOL','QG_SOL':'Num_Usinas_SOL', 'QG_BIO':'Num_Usinas_BIO'}\n","    typeGenRegDic = {'Norte':['QG_UHE','QG_EOL','QG_SOL','QG_UTE'],'Nordeste':['QG_UHE','QG_EOL','QG_SOL','QG_UTE'],'Sudeste-Centro-Oeste':['QG_UHE','QG_EOL','QG_SOL','QG_UTE','QG_BIO'],'Sul':['QG_UHE','QG_EOL','QG_UTE','QG_BIO'], 'AC-RO':['QG_UHE','QG_UTE']}\n","    typeGenRegDic_MW = {'Norte':['PG_UHE','PG_EOL','PG_SOL','PG_UTE'],'Nordeste':['PG_UHE','PG_EOL','PG_SOL','PG_UTE'],'Sudeste-Centro-Oeste':['PG_UHE','PG_EOL','PG_SOL','PG_UTE','PG_BIO'],'Sul':['PG_UHE','PG_EOL','PG_UTE','PG_BIO'], 'AC-RO':['PG_UHE','PG_UTE']}\n","    typeGenDic_MW = {'PG_UHE':'Num_Usinas_UHE', 'PG_UTE':'Num_Usinas_UTE', 'PG_EOL':'Num_Usinas_EOL','PG_SOL':'Num_Usinas_SOL', 'PG_BIO':'Num_Usinas_BIO'}\n","\n","    for reg in regioes:\n","        plot_Potencia(DF_REGIONAL_GER.loc[:,:,reg]['QG_MVAR'], '(MVAR)', 'POTENCIA REATIVA GERADA (MVAR) - ' + reg, limites=None)\n","        plot_Potencia(DF_REGIONAL_GER.loc[:,:,reg]['PG_MW'], '(MW)', 'POTENCIA ATIVA GERADA (MW) - ' + reg, limites=None)\n","        for tog in typeGenRegDic[reg]:\n","            numUsinas = DF_REGIONAL_GER.loc[:,:,reg][typeGenDic[tog]][0]\n","            nome = str('MVAR ' + reg.replace('-',' ')  + ' (' + tog.replace('_','-') + ') - Numero de Usinas ' + str(int(numUsinas)))\n","            plot_Potencia(DF_REGIONAL_GER.loc[:,:,reg][tog], '(MVAR)', nome , limites=None)\n","\n","        for tog in typeGenRegDic_MW[reg]:\n","            numUsinas = DF_REGIONAL_GER.loc[:,:,reg][typeGenDic_MW[tog]][0]\n","            nome = str('MW ' + reg.replace('-',' ')  + ' (' + tog.replace('_','-') + ') - Numero de Usinas ' + str(int(numUsinas)))\n","            plot_Potencia(DF_REGIONAL_GER.loc[:,:,reg][tog], '(MW)', nome , limites=None)"]},{"cell_type":"markdown","metadata":{},"source":["### b) Tensão no SIN boxplot"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def boxplot_barrasGeracao(Df_VF):\n","    \n","    Df_groupbyUF = Df_VF.groupby(by = ['Gen_Type']).agg({'BUS_ID': 'unique', 'MODV_PU': list,})\n","    Df_groupbyReg = Df_VF.groupby(by = ['REG']).agg({'BUS_ID': 'unique', 'MODV_PU': list,})\n","    #***************************************************************************************************\n","    data =  Df_groupbyUF['MODV_PU'][['UHE', 'UTE', 'PCH', 'EOL', 'UFV', 'BIO']] \n","    Nbarras = Df_groupbyUF['BUS_ID'][['UHE', 'UTE', 'PCH', 'EOL', 'UFV', 'BIO']]\n","    labels = ['Hydro','Thermal','SHP', 'Wind', 'Solar', 'Bio']  # Tus etiquetas de datos\n","    title = 'Bus Voltage Distribution by Type of Generation'  # Tu título\n","    xlabel = 'Type of Generation'  # Tu etiqueta del eje x\n","    ylabel = 'Voltage (pu)'  # Tu etiqueta del eje y\n","    # plot_boxplot(data, labels, title, xlabel, ylabel,text= True, nbarra = Nbarras)#limites = [0.88,1.125]\n","    #***************************************************************************************************\n","    Nbarras = Df_groupbyReg['BUS_ID'][['Norte','Nordeste','Sudeste-Centro-Oeste','Sul','AC-RO']]\n","    data = Df_groupbyReg['MODV_PU'][['Norte','Nordeste','Sudeste-Centro-Oeste','Sul','AC-RO']]\n","    labels = ['North', 'Northeast', 'SE-CW', 'South','AC-RO']  # Tus etiquetas de datos\n","    title = 'Bus Voltage Distribution by Region for Voltage-Controled Buses'  # Tu título\n","    xlabel = 'Region'  # Tu etiqueta del eje x\n","    ylabel = 'Voltage (pu)'  # Tu etiqueta del eje y\n","    # plot_boxplot(data, labels, title, xlabel, ylabel,text= True, nbarra = Nbarras)#, limites = [0.82,1.18]\n","\n","def boxplot_barrasCarga(Df_Vfpt):\n","\n","    #***************************************************************************************************\n","    V_NT = Df_Vfpt.groupby(by = ['VBASEKV']).agg({'BUS_ID': 'unique', 'MODV_PU': list,})\n","    n_bar = V_NT['BUS_ID'][[138,230,345,440,500,525,765]]\n","    numbarra = list(n_bar)\n","    data = V_NT['MODV_PU'][[138,230,345,440,500,525,765]]\n","    labels = ['138','230','345','440','500','525','765']  # Tus etiquetas de datos\n","    title = 'Bus Voltage Distribution by Voltage Level'  # Tu título\n","    xlabel = 'Voltage Level (kV)'  # Tu etiqueta del eje x\n","    ylabel = 'Voltage (pu)'  # Tu etiqueta del eje y\n","    # plot_boxplot(data, labels, title, xlabel, ylabel, text=True, nbarra = numbarra)#limites = [0.95, 1.105]\n","    #***************************************************************************************************\n","    Df_groupbyReg = Df_Vfpt.groupby(by = ['REG']).agg({'BUS_ID': 'unique', 'MODV_PU': list,})\n","    Nbarras = Df_groupbyReg['BUS_ID'][['Norte','Nordeste','Sudeste-Centro-Oeste','Sul','AC-RO']]\n","    data = Df_groupbyReg['MODV_PU'][['Norte','Nordeste','Sudeste-Centro-Oeste','Sul','AC-RO']]\n","    labels =  ['North', 'Northeast', 'SE-CW', 'South','AC-RO']  # Tus etiquetas de datos\n","    title = 'Bus Voltage Distribution by Region for Load Buses'  # Tu título\n","    xlabel = 'Region'  # Tu etiqueta del eje x\n","    ylabel = 'Voltage (pu)'  # Tu etiqueta del eje y\n","    # plot_boxplot(data, labels, title, xlabel, ylabel,text= True, nbarra = Nbarras)#, limites = [0.82,1.18]\n","\n","def plottensaoG():\n","    Df_VF = processdata.Df_VF\n","    DFF_Geral = Df_VF[(Df_VF['VBASEKV'].isin([138,230,345,440,500,525,765])) | (Df_VF['Gen_Type'].isin(['UHE', 'UTE', 'PCH', 'EOL', 'UFV', 'BIO']))] \n","    filtro1 = (DFF_Geral[['Dia', 'Hora']].apply(tuple, axis=1).isin(bool_PWF_NConv))\n","    DFF_Geral_PWFC = DFF_Geral[~filtro1]\n","\n","    # DFF_Geral_PWFC['MODV_PU'].to_csv(cenario+'/Voltage.csv', index=None)\n","\n","    data = [DFF_Geral_PWFC['MODV_PU'].values]  # Tu conjunto de datos\n","    labels = ['G. Sincrona']  # Tus etiquetas de datos\n","    title = 'Bus Voltage Distribution of the System'  # Tu título\n","    xlabel = 'Voltage (pu)'  # Tu etiqueta del eje x\n","    ylabel = 'Bus Voltages'  # Tu etiqueta del eje y\n","\n","    # plot_boxplot(data, labels, title, xlabel, ylabel, vert = False, text=True, rotation = 0)\n","\n","    # Q1 = np.percentile(data, 25)\n","    # Q3 = np.percentile(data, 75)\n","    # print(f'Primer cuartil (Q1): {Q1}')\n","    # print(f'Tercer cuartil (Q3): {Q3}')\n","    # IQR = Q3 - Q1\n","    # limite_inferior = Q1 - 1.5 * IQR\n","    # limite_superior = Q3 + 1.5 * IQR\n","    # print(f'El límite inferior es: {limite_inferior}')\n","    # print(f'El límite superior es: {limite_superior}')\n","\n","def plottensaoPR():\n","    df_ger = df_Final_ger[df_Final_ger['Gen_Type'].isin(['UHE', 'UTE', 'PCH', 'EOL', 'UFV', 'BIO'])]\n","    filtro1 = (df_ger[['Dia', 'Hora']].apply(tuple, axis=1).isin(bool_PWF_NConv))\n","    df_Final_ger_PWFC = df_ger[~filtro1]\n","    df_Final_ger_PWFC[['BUS_ID','ARE', 'MODV_PU', 'ANGV_DEG','PG_MW', 'QG_MVAR','Dia', 'Hora', 'U_FED', 'Gen_Type', 'REG', 'B0_MVAR', 'ST', 'SHUNT_INST_IND', 'SHUNT_INST_CAP', 'ReservaIND', 'ReservaCAP']].to_csv(cenario+'/Df_ger.csv', index=None)\n","\n","    df_nt = df_Final_nt[df_Final_nt['VBASEKV'].isin([138,230,345,440,500,525,765])]\n","    filtro2 = (df_nt[['Dia', 'Hora']].apply(tuple, axis=1).isin(bool_PWF_NConv))\n","    df_Final_nt_PWFC = df_nt[~filtro2]\n","    df_Final_nt_PWFC[['BUS_ID','ARE', 'MODV_PU', 'ANGV_DEG','VBASEKV', 'PL_MW', 'QL_MVAR','Dia', 'Hora', 'U_FED', 'REG', 'B0_MVAR', 'ST', 'SHUNT_INST_IND', 'SHUNT_INST_CAP','ReservaINDshunt', 'ReservaCAPshunt']].to_csv(cenario+'/Df_nt.csv', index=None)\n","    \n","    # boxplot_barrasCarga(df_Final_nt_PWFC)\n","    # boxplot_barrasGeracao(df_Final_ger_PWFC)\n","\n","if ConvergenceAnalise:\n","    if Plot_Tensao_Geral:\n","        plottensaoG()\n","        plottensaoPR()\n"]},{"cell_type":"markdown","metadata":{},"source":["# Mapas"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# df = pd.read_csv('RECURSOS/InfoBarras.csv',sep=';')\n","# df1 = pd.read_csv('C:/Users/David/OneDrive/Desktop/CHRISTOPHER/GeoINFO_BusesSIN.csv', sep= ';')\n","# # Suponiendo que 'df' es tu DataFrame\n","# df1 = df1.drop(df1.columns[0], axis=1)\n","# df2 = df[['BUS_ID','BUS_NAME','Gen_Type','Latitude','Longitude']].merge(df1[['BUS_ID','U_FED','REG']], on='BUS_ID').drop_duplicates()\n","# df2.to_csv('RECURSOS/GeoINFO_BusesSIN.csv', sep=';')\n","# processdata.Df_VF.to_csv('Df_VF.csv', index=None)\n","# dff_NT_map.to_csv('dff_NT_map.csv', index=None)\n","# dff_Ger_map.to_csv('dff_Ger_map.csv', index=None)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from Maps import *\n","if MapasAnalise:\n","    Df_VF = processdata.Df_VF\n","    options = {'Limit Violations All': True, 'Mean and Variance': True, 'Limit Violations by Group': True, 'HeatMap by state 1': True, 'Limit Violations PO': False}\n","    Maps(Df_VF, dff_NT_map, dff_Ger_map, cenario, options)"]},{"cell_type":"markdown","metadata":{},"source":["# STATIC ASSESMENT"]},{"cell_type":"markdown","metadata":{},"source":["## a) Calculo do Indice de tensão"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if ComputeDPI:\n","    from computeDPI import *\n","\n","    print('CALCULO DO DPI para todos os Cenários:')\n","    ts = 0.8\n","    tb = 1\n","    VVI = computeDPI(df_Final_nt, df_Final_ger, ts, tb, p_norm = 2, p_inf = False, NBcv = True)\n","    dfPQ_CSI = VVI.dfPQ_CSI\n","    dfPV_CSI = VVI.dfPV_CSI\n","    df_PQ_reg = VVI.df_PQ_reg\n","    df_PV_reg = VVI.df_PV_reg\n","    df_busPQ = VVI.df_busPQ\n","    df_busPV = VVI.df_busPV\n","    n_maior = VVI.n_maior\n","\n","    dfPQ_CSI = dfPQ_CSI.groupby(['Dia' , 'Hora', 'REG']).first()\n","    dfPV_CSI = dfPV_CSI.groupby(['Dia' , 'Hora', 'REG']).first()\n","    dffPQgb = df_PQ_reg.groupby(by=['Dia','Hora','REG','VBASEKV']).agg({'CSI_INF':'first','CSI_SUP':'first'})\n","    dffPVgb = df_PV_reg.groupby(by=['Dia','Hora','REG','Gen_Type']).agg({'CSI_INF':'first','CSI_SUP':'first'})\n","\n","    if ConvergenceAnalise:\n","        for index in bool_PWF_NConv:\n","            dfPQ_CSI.drop((index[0], index[1]), inplace=True)\n","            dfPV_CSI.drop((index[0], index[1]), inplace=True)\n","            dffPQgb.drop((index[0], index[1]), inplace=True)\n","            dffPVgb.drop((index[0], index[1]), inplace=True)\n","        filtro1 = (df_busPQ[['Dia', 'Hora']].apply(tuple, axis=1).isin(bool_PWF_NConv))\n","        df_busPQ_mod = df_busPQ[~filtro1].copy()\n","        filtro2 = (df_busPV[['Dia', 'Hora']].apply(tuple, axis=1).isin(bool_PWF_NConv))\n","        df_busPV_mod = df_busPV[~filtro2].copy()\n","    else:\n","        df_busPQ_mod = df_busPQ\n","        df_busPV_mod = df_busPV\n","        \n","    dffPQgb.to_csv(cenario+'/Indice_DecompPQ.csv',index = True)\n","    dffPVgb.to_csv(cenario+'/Indice_DecompPV.csv',index = True)"]},{"cell_type":"markdown","metadata":{},"source":["## b) Resumo Indice "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if ComputeDPI:\n","    n=2\n","\n","    dfPQ_CSI['DPI_2N_INF'] = dfPQ_CSI['CSI_INF_FINAL'].pow(2*n) \n","    dfPQ_CSI['DPI_2N_SUP'] = dfPQ_CSI['CSI_SUP_FINAL'].pow(2*n) \n","    dfPV_CSI['DPI_2N_INF'] = dfPV_CSI['CSI_INF_FINAL'].pow(2*n) \n","    dfPV_CSI['DPI_2N_SUP'] = dfPV_CSI['CSI_SUP_FINAL'].pow(2*n) \n","    ddf_pq = dfPQ_CSI.reset_index().groupby(by = ['Dia','Hora']).agg({'DPI_2N_INF':  'sum', 'DPI_2N_SUP':  'sum'})\n","    ddf_pq['PQ_lower'] = ddf_pq['DPI_2N_INF'].pow(1/(2*n))\n","    ddf_pq['PQ_upper'] = ddf_pq['DPI_2N_SUP'].pow(1/(2*n))\n","    ddf_pv = dfPV_CSI.reset_index().groupby(by = ['Dia','Hora']).agg({'DPI_2N_INF':  'sum', 'DPI_2N_SUP':  'sum'})\n","    ddf_pv['PV_lower'] = ddf_pv['DPI_2N_INF'].pow(1/(2*n))\n","    ddf_pv['PV_upper'] = ddf_pv['DPI_2N_SUP'].pow(1/(2*n))\n","    DF_DPI_pq_pv_ul = pd.concat([ddf_pv[['PV_lower','PV_upper']],ddf_pq[['PQ_lower','PQ_upper']]], axis=1)\n","    DF_DPI_pq_pv_ul.to_csv(cenario+'/Indice_Modif.csv')\n","\n","    # ==========================================================================================================================\n","    dfPQ_CSI['DPI_2N_INF'] = dfPQ_CSI['CSI_INF_FINAL'].pow(2*n) \n","    dfPQ_CSI['DPI_2N_SUP'] = dfPQ_CSI['CSI_SUP_FINAL'].pow(2*n) \n","    dfPV_CSI['DPI_2N_INF'] = dfPV_CSI['CSI_INF_FINAL'].pow(2*n) \n","    dfPV_CSI['DPI_2N_SUP'] = dfPV_CSI['CSI_SUP_FINAL'].pow(2*n) \n","\n","    df_DPI_PO_ = dfPQ_CSI['DPI_2N_INF'] + dfPQ_CSI['DPI_2N_SUP'] + dfPV_CSI['DPI_2N_INF'] +  dfPV_CSI['DPI_2N_SUP'] \n","    df_DPI_PO = pd.DataFrame(df_DPI_PO_)\n","    df_DPI_PO = df_DPI_PO.reset_index().groupby(by = ['Dia','Hora']).agg(DPI_PO =(0, 'sum'))\n","    df_DPI_PO['DPI_PO_final']= df_DPI_PO['DPI_PO'].pow(1/(2*n))\n","    df_DPI_PO['DPI_PO_final'].to_csv(cenario+'/Indice_PO.csv')\n","\n","    plot_indice_0 (df_DPI_PO, r'$\\mathrm{DPI}$', 'DPI_PO_final','','DPI_PO_final', order=True, ylimites=[-0.05, 1.5] )\n","    (df_DPI_PO[df_DPI_PO['DPI_PO_final']>1].index.to_frame()[['Dia', 'Hora']].apply(tuple, axis=1)).to_csv(cenario + '/PO_Inseguros.txt', index = None)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if ComputeDPI:\n","    if resumoIndice:\n","        if ConvergenceAnalise:\n","            path_txt = cenario + '/RelatorioIndiceG.txt'\n","            numeroPO = len(set(dfPQ_CSI.index.to_frame()[['Dia','Hora']].apply(tuple, axis=1).values))\n","            DFS_INS = [dfPQ_CSI[dfPQ_CSI['CSI_INF_FINAL']>1],\n","                    dfPQ_CSI[dfPQ_CSI['CSI_SUP_FINAL']>1],\n","                    dfPV_CSI[dfPV_CSI['CSI_INF_FINAL']>1],\n","                    dfPV_CSI[dfPV_CSI['CSI_SUP_FINAL']>1]]\n","            CasosInseguros = pd.concat(DFS_INS, axis=0,)\n","            CasosInseguros = CasosInseguros.sort_index()\n","            lista = [index[:2] for index in CasosInseguros.index]\n","            conjunto_filtros_INSG = set(map(tuple, lista))\n","            filtro1 = (OPF_NC[['Dia', 'Hora']].apply(tuple, axis=1).isin(conjunto_filtros_INSG))\n","            OPF_Filtrado = OPF_NC[filtro1]\n","            filtro2 = (PWF_CV[['Dia', 'Hora']].apply(tuple, axis=1).isin(conjunto_filtros_INSG))\n","            PWF_Filtrado = PWF_CV[filtro2]\n","            print('Numero de casos com indice >  1, INSEGUROS: ' + str(len(conjunto_filtros_INSG)) + '=> ' + str(round(len(conjunto_filtros_INSG)/numeroPO*100,2)))\n","            print('====================================================================')\n","            print('Numero de casos com indice >  1 que são não Convergidos no OPF: ' + str(len(OPF_Filtrado)) + '=> ' + str(round(len(OPF_Filtrado)/numeroPO*100,2)) )\n","            with open(path_txt, 'w') as f:\n","                f.write('Numero de casos com indice >  1, INSEGUROS:' + str(len(conjunto_filtros_INSG)) + '=> ' + str(round(len(conjunto_filtros_INSG)/numeroPO*100,2)) + '\\n')\n","                f.write('Numero de casos com indice >  1 que são não Convergidos no OPF: ' + str(len(OPF_Filtrado)) + '=> ' + str(round(len(OPF_Filtrado)/numeroPO*100,2)) + '\\n' )\n","            \n","            DFS_ALARM = [dfPQ_CSI[(dfPQ_CSI['CSI_INF_FINAL']<=1) & (dfPQ_CSI['CSI_INF_FINAL']>0)],\n","                        dfPQ_CSI[(dfPQ_CSI['CSI_SUP_FINAL']<=1) & (dfPQ_CSI['CSI_SUP_FINAL']>0)],\n","                        dfPV_CSI[(dfPV_CSI['CSI_INF_FINAL']<=1) & (dfPV_CSI['CSI_INF_FINAL']>0)],\n","                        dfPV_CSI[(dfPV_CSI['CSI_SUP_FINAL']<=1) & (dfPV_CSI['CSI_SUP_FINAL']>0)]]\n","\n","            CasosAlarme = pd.concat(DFS_ALARM, axis=0,)\n","            filtroalarme = (CasosAlarme.index.to_frame()[['Dia', 'Hora']].apply(tuple, axis=1).isin(conjunto_filtros_INSG))\n","            CasosAlarme = CasosAlarme[~filtroalarme]\n","            CasosAlarme = CasosAlarme.sort_index()\n","            lista = [index[:2] for index in CasosAlarme.index]\n","            conjunto_filtros_ALRM = set(map(tuple, lista))\n","            filtro1 = (OPF_NC[['Dia', 'Hora']].apply(tuple, axis=1).isin(conjunto_filtros_ALRM))\n","            OPF_Filtrado = OPF_NC[filtro1]\n","            filtro2 = (PWF_CV[['Dia', 'Hora']].apply(tuple, axis=1).isin(conjunto_filtros_ALRM))\n","            PWF_Filtrado = PWF_CV[filtro2]\n","            print('====================================================================')\n","            print('Numero de casos com indice  ALARME: ' + str(len(conjunto_filtros_ALRM)) + '=> ' + str(round(len(conjunto_filtros_ALRM)/numeroPO*100,2)))\n","            print('====================================================================')\n","            print('Numero de casos com indice ALARME que são não Convergidos no OPF: ' + str(len(OPF_Filtrado)) + '=> ' + str(round(len(OPF_Filtrado)/numeroPO*100,2)))\n","            with open(path_txt, 'a') as f:\n","                    f.write('Numero de casos com indice ALARME:' + str(len(conjunto_filtros_ALRM)) + '=> ' + str(round(len(conjunto_filtros_ALRM)/numeroPO*100,2)) + '\\n')\n","                    f.write('Numero de casos com indice ALARME que são não Convergidos no OPF: ' + str(len(OPF_Filtrado)) + '=> ' + str(round(len(OPF_Filtrado)/numeroPO*100,2)) + '\\n' )\n","            \n","            # ===========================================================================================================================================================\n","            def print_results(df_CSI, tipo_analise):\n","                with open(path_txt, 'a') as output_file:\n","                    output_file.write(f'******** RESULTADOS BARRAS {tipo_analise} INSEGURO ********\\n')\n","                    tipo_sup_inf = 'CSI_SUP_FINAL' if 'SOBRETENSÃO' in tipo_analise else 'CSI_INF_FINAL'\n","                    \n","                    for i in df_Final_nt['REG'].unique():\n","                        indregsuperior = df_CSI[df_CSI[tipo_sup_inf] > 1]\n","                        try:\n","                            output_file.write(f'casos com índice acima de 1 na região {i}: {len(set(map(tuple, indregsuperior.loc[:, :, i].index)))}\\n')\n","                        except:\n","                            output_file.write(f'NÃO TEM casos com índice acima de 1 na região {i}\\n')\n","                            pass\n","\n","            print_results(dfPQ_CSI, 'BARRAS PQ SOBRETENSÃO')\n","            print_results(dfPV_CSI, 'BARRAS PV SOBRETENSÃO')\n","            print_results(dfPQ_CSI, 'BARRAS PQ SUBTENSÃO')\n","            print_results(dfPV_CSI, 'BARRAS PV SUBTENSÃO')\n","            \n","            # ===========================================================================================================================================================\n","            print('===========================SUBTENSÃO==============================')\n","            DFS_INS = [dfPQ_CSI[dfPQ_CSI['CSI_INF_FINAL']>1],\n","                    dfPV_CSI[dfPV_CSI['CSI_INF_FINAL']>1]]\n","            CasosInseguros = pd.concat(DFS_INS, axis=0,)\n","            CasosInseguros = CasosInseguros.sort_index()\n","            lista = [index[:2] for index in CasosInseguros.index]\n","            conjunto_filtros_INSG = set(map(tuple, lista))\n","            filtro1 = (OPF_NC[['Dia', 'Hora']].apply(tuple, axis=1).isin(conjunto_filtros_INSG))\n","            OPF_Filtrado = OPF_NC[filtro1]\n","            filtro2 = (PWF_CV[['Dia', 'Hora']].apply(tuple, axis=1).isin(conjunto_filtros_INSG))\n","            PWF_Filtrado = PWF_CV[filtro2]\n","            print('Numero de casos com indice >  1, INSEGUROS: ' + str(len(conjunto_filtros_INSG)) + '=> ' + str(round(len(conjunto_filtros_INSG)/1344*100,2)))\n","            print('====================================================================')\n","            print('Numero de casos com indice >  1 que são não Convergidos no OPF: ' + str(len(OPF_Filtrado)) + '=> ' + str(round(len(OPF_Filtrado)/1344*100,2)) )\n","\n","            DFS_ALARM = [dfPQ_CSI[(dfPQ_CSI['CSI_INF_FINAL']<=1) & (dfPQ_CSI['CSI_INF_FINAL']>0)],\n","                        dfPV_CSI[(dfPV_CSI['CSI_INF_FINAL']<=1) & (dfPV_CSI['CSI_INF_FINAL']>0)],]\n","\n","            CasosAlarme = pd.concat(DFS_ALARM, axis=0,)\n","            filtroalarme = (CasosAlarme.index.to_frame()[['Dia', 'Hora']].apply(tuple, axis=1).isin(conjunto_filtros_INSG))\n","            CasosAlarme = CasosAlarme[~filtroalarme]\n","            CasosAlarme = CasosAlarme.sort_index()\n","            lista = [index[:2] for index in CasosAlarme.index]\n","            conjunto_filtros_ALRM = set(map(tuple, lista))\n","            filtro1 = (OPF_NC[['Dia', 'Hora']].apply(tuple, axis=1).isin(conjunto_filtros_ALRM))\n","            OPF_Filtrado = OPF_NC[filtro1]\n","            filtro2 = (PWF_CV[['Dia', 'Hora']].apply(tuple, axis=1).isin(conjunto_filtros_ALRM))\n","            PWF_Filtrado = PWF_CV[filtro2]\n","            print('====================================================================')\n","            print('Numero de casos com indice  ALARME: ' + str(len(conjunto_filtros_ALRM)) + '=> ' + str(round(len(conjunto_filtros_ALRM)/1344*100,2)))\n","            print('====================================================================')\n","            print('Numero de casos com indice ALARME que são não Convergidos no OPF: ' + str(len(OPF_Filtrado)) + '=> ' + str(round(len(OPF_Filtrado)/1344*100,2)))\n","            \n","            # ===========================================================================================================================================================\n","            print('===========================SOBRETENSÃO==============================')\n","            DFS_INS = [dfPQ_CSI[dfPQ_CSI['CSI_SUP_FINAL']>1],\n","                    dfPV_CSI[dfPV_CSI['CSI_SUP_FINAL']>1]]\n","            CasosInseguros = pd.concat(DFS_INS, axis=0,)\n","            CasosInseguros = CasosInseguros.sort_index()\n","            lista = [index[:2] for index in CasosInseguros.index]\n","            conjunto_filtros_INSG = set(map(tuple, lista))\n","            filtro1 = (OPF_NC[['Dia', 'Hora']].apply(tuple, axis=1).isin(conjunto_filtros_INSG))\n","            OPF_Filtrado = OPF_NC[filtro1]\n","            filtro2 = (PWF_CV[['Dia', 'Hora']].apply(tuple, axis=1).isin(conjunto_filtros_INSG))\n","            PWF_Filtrado = PWF_CV[filtro2]\n","            print('Numero de casos com indice >  1, INSEGUROS: ' + str(len(conjunto_filtros_INSG)) + '=> ' + str(round(len(conjunto_filtros_INSG)/1344*100,2)))\n","            print('====================================================================')\n","            print('Numero de casos com indice >  1 que são não Convergidos no OPF: ' + str(len(OPF_Filtrado)) + '=> ' + str(round(len(OPF_Filtrado)/1344*100,2)) )\n","\n","            DFS_ALARM = [dfPQ_CSI[(dfPQ_CSI['CSI_SUP_FINAL']<=1) & (dfPQ_CSI['CSI_SUP_FINAL']>0)],\n","                        dfPV_CSI[(dfPV_CSI['CSI_SUP_FINAL']<=1) & (dfPV_CSI['CSI_SUP_FINAL']>0)],]\n","\n","            CasosAlarme = pd.concat(DFS_ALARM, axis=0,)\n","            filtroalarme = (CasosAlarme.index.to_frame()[['Dia', 'Hora']].apply(tuple, axis=1).isin(conjunto_filtros_INSG))\n","            CasosAlarme = CasosAlarme[~filtroalarme]\n","            CasosAlarme = CasosAlarme.sort_index()\n","            lista = [index[:2] for index in CasosAlarme.index]\n","            conjunto_filtros_ALRM = set(map(tuple, lista))\n","            filtro1 = (OPF_NC[['Dia', 'Hora']].apply(tuple, axis=1).isin(conjunto_filtros_ALRM))\n","            OPF_Filtrado = OPF_NC[filtro1]\n","            filtro2 = (PWF_CV[['Dia', 'Hora']].apply(tuple, axis=1).isin(conjunto_filtros_ALRM))\n","            PWF_Filtrado = PWF_CV[filtro2]\n","            print('====================================================================')\n","            print('Numero de casos com indice  ALARME: ' + str(len(conjunto_filtros_ALRM)) + '=> ' + str(round(len(conjunto_filtros_ALRM)/1344*100,2)))\n","            print('====================================================================')\n","            print('Numero de casos com indice ALARME que são não Convergidos no OPF: ' + str(len(OPF_Filtrado)) + '=> ' + str(round(len(OPF_Filtrado)/1344*100,2)))"]},{"cell_type":"markdown","metadata":{},"source":["## c) Graficos DPI por região"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.rcParams[\"font.family\"] = \"Times New Roman\"\n","paletadcolor = sns.color_palette()\n","\n","if plotDPI:\n","    def plot_indice (df_data, eje_y, name, title, INDICE, xlimites=None,ylimites=None, display_ = False, order = False):\n","\n","        if display_:\n","            display(df_data[df_data[INDICE]==df_data[INDICE].max()].T)\n","        \n","        fig, axs = plt.subplots(nrows=1, figsize=(10, 6), sharex=False)\n","        colores = [sns.color_palette(\"Paired\")[1], sns.color_palette(\"Paired\")[3], sns.color_palette(\"Paired\")[5],sns.color_palette(\"Paired\")[7],sns.color_palette(\"Paired\")[9]]\n","        region_map = {'Nordeste':'Northeast', 'Norte':'North', 'Sudeste-Centro-Oeste':'SE-CW', 'Sul':'South','AC-RO':'AC-RO'}\n","        for idx, regiao in enumerate(['Norte','Nordeste','Sudeste-Centro-Oeste', 'Sul', 'AC-RO']):\n","        # for idx, regiao in enumerate(['Nordeste']):\n","\n","            if order:\n","                data = df_data.loc[:, :, regiao].sort_values(INDICE, ascending=False)[INDICE]\n","                data_points_per_day = 10\n","                num_days = 1344*data_points_per_day / 100\n","                axs.set_xticks([round(i * num_days) for i in range(data_points_per_day+1)])\n","                axs.set_xticklabels([f'{i*10}' for i in range(data_points_per_day+1)], fontsize=12, rotation=0, ha='center')\n","            else:\n","                data = df_data.loc[:, :, regiao][INDICE]\n","                data_points_per_day = 48\n","                num_days = len(data) // data_points_per_day\n","                axs.set_xticks([i * data_points_per_day for i in range(num_days)])\n","                axs.set_xticklabels([f'{i+1}' for i in range(num_days)], fontsize=18, rotation=0, ha='center')\n","            \n","            axs.plot(data.values, color=colores[idx], label=region_map[regiao], lw=2, linestyle='-')\n","            \n","        axs.legend(loc='upper right', fontsize=18)\n","        axs.tick_params(axis='y', labelsize=24)\n","        axs.tick_params(axis='x', labelsize=18)\n","        axs.set_xlabel('Percentage of half hours in a month (%)', fontsize=23)\n","        axs.set_ylabel(eje_y, fontsize=22)\n","        axs.set_title(title, fontsize=22)\n","        if xlimites != None:\n","            axs.set_xlim(xlimites)\n","        if ylimites != None:\n","            axs.set_ylim(ylimites)\n","        axs.grid(True, linestyle='-', linewidth=1.2, alpha=0.4)\n","        plt.tight_layout()\n","        nome = cenario + '/Indice/' + name + '.svg'\n","        plt.savefig(nome)\n","        nome = cenario + '/Indice/' + name + '.png'\n","        plt.savefig(nome, bbox_inches = 'tight')\n","        plt.show()\n","\n","    plot_indice (dfPQ_CSI, r'$\\mathrm{DPI}_\\mathrm{PQ}^\\mathrm{u}$', 'DPI_(u)_PQ','','CSI_SUP_FINAL', order=True, ylimites=[0, 1])\n","    plot_indice (dfPQ_CSI, r'$\\mathrm{DPI}_\\mathrm{PQ}^\\mathrm{l}$', 'DPI_(l)_PQ','', 'CSI_INF_FINAL', order=True, ylimites=[0, 1])\n","    plot_indice (dfPV_CSI, r'$\\mathrm{DPI}_\\mathrm{PV}^\\mathrm{u}$', 'DPI_(u)_PV' ,'','CSI_SUP_FINAL', order=True, ylimites=[0, 1])\n","    plot_indice (dfPV_CSI, r'$\\mathrm{DPI}_\\mathrm{PV}^\\mathrm{l}$', 'DPI_(l)_PV', '','CSI_INF_FINAL', order=True, ylimites=[0, 1])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if plotDPI:\n","\n","    def plot_indice_1 (df_pv, df_pq, eje_y, title, regiao, limites=None, order = True):\n","\n","        fig, axs = plt.subplots(nrows=1, figsize=(10, 6))\n","        colores = [paletadcolor[4], paletadcolor[0], paletadcolor[3],paletadcolor[2],paletadcolor[3]]\n","        for idx, INDICE in enumerate(['CSI_SUP_FINAL', 'CSI_INF_FINAL']):\n","            if order:\n","                datapq = df_pq.loc[:, :, regiao][INDICE]\n","                datapv = df_pv.loc[:, :, regiao][INDICE]\n","            else:\n","                datapq = df_pq.loc[:, :, regiao].sort_values(INDICE, ascending=False)[INDICE]\n","                datapv = df_pv.loc[:, :, regiao].sort_values(INDICE, ascending=False)[INDICE]\n","                \n","            axs.plot(datapq.values, color=colores[idx], label='PQ_'+ INDICE[4:7],lw=2, linestyle='-')\n","            axs.plot(datapv.values, color=colores[idx+2], label='PV_'+ INDICE[4:7],lw=2, linestyle='-')\n","\n","        axs.legend(loc='best', fontsize=18)\n","        # # Calculate the number of data points in a day (assuming each day has 48 data points)\n","        # data_points_per_day = 48\n","        # # Calculate the number of days based on the length of the data\n","        # num_days = len(datapq) // data_points_per_day\n","        # # Set x-axis ticks and labels for each day\n","        # axs.set_xticks([i * data_points_per_day for i in range(num_days)])\n","        # axs.set_xticklabels([f'{i+1}' for i in range(num_days)], fontsize=12, rotation=0, ha='right')\n","        axs.tick_params(axis='y', labelsize=18)\n","        axs.tick_params(axis='x', labelsize=18)\n","        axs.set_xlabel('Operating points', fontsize=23)\n","        axs.set_ylabel(eje_y, fontsize=20)\n","        axs.set_title(title, fontsize=25)\n","        if limites != None:\n","            axs.set_ylim(limites)\n","        axs.grid(True, linestyle='--', linewidth=1, alpha=0.2)\n","        plt.tight_layout()\n","        nome = cenario + '/Indice/' + title + '.svg'\n","        plt.savefig(nome)\n","        nome = cenario + '/Indice/' + title + '.png'\n","        plt.savefig(nome, bbox_inches = 'tight')\n","        plt.show()\n","\n","    plot_indice_1 (dfPV_CSI, dfPQ_CSI, 'DPI', 'North','Norte',order=False)#limites=[0,1.3]\n","    plot_indice_1 (dfPV_CSI, dfPQ_CSI, 'DPI', 'Northeast','Nordeste',order=False )#limites=[0,1.3], limites=[-0.1,2]\n","    plot_indice_1 (dfPV_CSI, dfPQ_CSI, 'DPI', 'Southeast Center West','Sudeste-Centro-Oeste',order=False)#limites=[0,1.3], limites=[-0.1,9]\n","    plot_indice_1 (dfPV_CSI, dfPQ_CSI, 'DPI', 'AC-RO','AC-RO',order=False)#limites=[0,1.3]\n","    plot_indice_1 (dfPV_CSI, dfPQ_CSI, 'DPI', 'South','Sul',order=False)#limites=[0,1.3], limites=[-0.1,1.5]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if plotDPI:\n","    def plot_indice_2 (df, eje_y, name ,title, regiao, INDICE, GB, limites=None, order = True):\n","\n","        fig, axs = plt.subplots(nrows=1, figsize=(10, 6))\n","        labelG = {'BIO': 'Bio', 'EOL': 'Wind', 'PCH': 'SHP','UFV': 'Solar', 'UHE': 'Hydro','UTE': 'Thermal', 'SIN': 'Synchronous C.'}\n","        if GB=='Gen_Type':\n","            colores = {'BIO': paletadcolor[4], 'EOL': paletadcolor[0], 'PCH': paletadcolor[3],'UFV': paletadcolor[2], 'UHE': paletadcolor[5],'UTE': paletadcolor[1], 'SIN': paletadcolor[6]}\n","        else:\n","            colores = {230: paletadcolor[4], 345: paletadcolor[0], 440: paletadcolor[3],500: paletadcolor[2], 525: paletadcolor[5], 765: paletadcolor[1]}\n","        data = df.loc[:, :, regiao]\n","        Busgroup = np.array(data.reset_index(GB)[GB].unique())\n","        print(Busgroup)\n","        for idx, G_bus in enumerate(Busgroup):\n","            if order:\n","                data_ = df.loc[:, :, regiao, G_bus][INDICE]\n","            else:\n","                data_ = df.loc[:, :, regiao, G_bus].sort_values(INDICE, ascending=False)[INDICE]\n","            if GB=='Gen_Type':\n","                label = labelG[G_bus]\n","            else:\n","                label = G_bus\n","            axs.plot(data_.values, color=colores[G_bus], label= label,lw=2)\n","\n","        axs.legend(loc='best', fontsize=14)\n","        # Calculate the number of data points in a day (assuming each day has 48 data points)\n","        data_points_per_day = 48\n","        # Calculate the number of days based on the length of the data\n","        num_days = len(data_) // data_points_per_day\n","        # Set x-axis ticks and labels for each day\n","        axs.set_xticks([i * data_points_per_day for i in range(num_days)])\n","        axs.set_xticklabels([f'{i+1}' for i in range(num_days)], fontsize=18, rotation=0, ha='center')\n","        axs.tick_params(axis='y', labelsize=18)\n","        # axs.tick_params(axis='x', labelsize=15)\n","        axs.set_xlabel('Days', fontsize=23)\n","        axs.set_ylabel(eje_y, fontsize=20)\n","        axs.set_title(title, fontsize=25)\n","        if limites != None:\n","            axs.set_ylim(limites)\n","        axs.grid(True, linestyle='-', linewidth=1.2, alpha=0.4)\n","        plt.tight_layout()\n","        nome = cenario + '/Indice/' + name + '.svg'\n","        plt.savefig(nome)\n","        nome = cenario + '/Indice/' + name + '.png'\n","        plt.savefig(nome, bbox_inches = 'tight')\n","        plt.show()\n","\n","    def main_plot_indice_2(dffPQgb, dffPVgb):\n","        regioes = df_PQ_reg['REG'].unique()\n","        region_map = {'Nordeste':'Northeast', 'Norte':'North', 'Sudeste-Centro-Oeste':'SE-CW', 'Sul':'South','AC-RO':'AC-RO'}\n","        for i in regioes:\n","            Indice = 'CSI_INF'\n","            plot_indice_2 (dffPQgb, r'$\\mathrm{DPI}_\\mathrm{PQ}^\\mathrm{l}$', 'DPI_(l)_PQ_' + region_map[i], region_map[i] ,i, Indice, 'VBASEKV',limites=[0,2.5])\n","            plot_indice_2 (dffPVgb, r'$\\mathrm{DPI}_\\mathrm{PV}^\\mathrm{l}$', 'DPI_(l)_PV_' + region_map[i], region_map[i] ,i, Indice, 'Gen_Type', limites=[0,2.5])\n","            Indice = 'CSI_SUP'\n","            plot_indice_2 (dffPQgb, r'$\\mathrm{DPI}_\\mathrm{PQ}^\\mathrm{u}$', 'DPI_(u)_PQ_' + region_map[i], region_map[i] ,i, Indice, 'VBASEKV',limites=[0,2.5])\n","            plot_indice_2 (dffPVgb, r'$\\mathrm{DPI}_\\mathrm{PV}^\\mathrm{u}$', 'DPI_(u)_PV_' + region_map[i], region_map[i] ,i, Indice, 'Gen_Type', limites=[0,2.5])\n","\n","    main_plot_indice_2(dffPQgb, dffPVgb)"]},{"cell_type":"markdown","metadata":{},"source":["## d) Graficos Barras CRITICAS Boxplot"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if BP_Criticalbuses:\n","\n","    def boxplot_plot_PB(dff_filtered_PQ, dff_filtered_PV, df_ind, condition):\n","\n","        dff_PQ =  dff_filtered_PQ.groupby(by=['REG','VBASEKV','BUS_NAME']).agg(Ocurrencies = ('VBASEKV','count'), \n","                                                                            MODV_PU = ('MODV_PU', list),\n","                                                                            MIN = ('MODV_PU', 'min'),\n","                                                                            MAX = ('MODV_PU', 'max')\n","                                                                            )\n","\n","        dff_PV =  dff_filtered_PV.groupby(by=['REG','Gen_Type','BUS_NAME']).agg(Ocurrencies = ('Gen_Type','count'), \n","                                                                            MODV_PU = ('MODV_PU', list),\n","                                                                            MIN = ('MODV_PU', 'min'),\n","                                                                            MAX = ('MODV_PU', 'max')\n","                                                                            )\n","        DF_dfss = [dff_PQ, dff_PV]\n","        name = ['PQ', 'PV']\n","        for idx, dff in enumerate(DF_dfss):\n","            regions = dff.index.get_level_values(0).unique()\n","            for Region in regions:\n","                nt = dff.loc[Region].index.get_level_values(0).unique()\n","                for vb in nt:\n","                    df_boxplot = dff.loc[Region,vb].sort_values(['Ocurrencies'], ascending = False)[:15]\n","                    minimo  = df_boxplot['MIN'].min() - 0.01\n","                    maximo =  df_boxplot['MAX'].max() + 0.01\n","                    numbuses =  condition + ' ' + Region + ' - ' + df_ind  + ' - ' +  name[idx] + ' - ' +  str(vb)  + ' - Buses with voltage problems = ' + str(dff.loc[Region,vb].shape[0]) \n","                    plot_boxplot(df_boxplot['MODV_PU'], df_boxplot.index, numbuses , 'BUSES', 'VOLTAGE (pu)', text = True, rotation=45, limites=[minimo,maximo])\n","                    \n","    def boxplot_problematic_buses(df_busPQ,df_busPV):\n","        \n","        dicIndice = ['IndiceInf','IndiceSup']\n","        for df_ind in dicIndice:\n","\n","            dff_filtered_PQ = df_busPQ[df_busPQ[df_ind]>1].sort_values(by=['REG','VBASEKV', 'BUS_NAME', 'MODV_PU'], ascending=[True, True, False, True])\n","            dff_filtered_PV = df_busPV[df_busPV[df_ind]>1].sort_values(by=['REG','Gen_Type', 'BUS_NAME', 'MODV_PU'], ascending=[True, True, False, True])\n","            boxplot_plot_PB(dff_filtered_PQ, dff_filtered_PV, df_ind, 'Inseguro')\n","\n","            dff_filtered_PQ = df_busPQ[(df_busPQ[df_ind]<=1) & (df_busPQ[df_ind]>0)].sort_values(by=['REG','VBASEKV', 'BUS_NAME', 'MODV_PU'], ascending=[True, True, False, True])\n","            dff_filtered_PV = df_busPV[(df_busPV[df_ind]<=1) & (df_busPV[df_ind]>0)].sort_values(by=['REG','Gen_Type', 'BUS_NAME', 'MODV_PU'], ascending=[True, True, False, True])\n","            boxplot_plot_PB(dff_filtered_PQ, dff_filtered_PV, df_ind, 'Alarme')\n","\n","    boxplot_problematic_buses(df_busPQ_mod,df_busPV_mod)"]},{"cell_type":"markdown","metadata":{},"source":["## e) Criação pastas e arquivos para simular no Organon"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if resumoIndice:\n","    df_busPQ_mod['BUS_ID'] = df_busPQ_mod['BUS_ID'].astype(int)\n","    df_busPV_mod['BUS_ID'] = df_busPV_mod['BUS_ID'].astype(int)\n","    df_busPV_mod[(df_busPV_mod['IndiceInf']>0.20)].groupby(by = ['REG'])['BUS_ID'].nunique().to_csv(cenario + '/Critical_infPVbuses.txt', header=True, index=True)\n","    df_busPQ_mod[(df_busPQ_mod['IndiceInf']>0.20)].groupby(by = ['REG'])['BUS_ID'].nunique().to_csv(cenario + '/Critical_infPQbuses.txt', header=True, index=True)\n","    df_busPV_mod[(df_busPV_mod['IndiceInf']>0.20)].groupby(by = ['REG'])['BUS_ID'].unique().to_csv(cenario + '/Critical_infPVbuses_bus.txt', header=True, index=True)\n","    df_busPQ_mod[(df_busPQ_mod['IndiceInf']>0.20)].groupby(by = ['REG'])['BUS_ID'].unique().to_csv(cenario + '/Critical_infPQbuses_bus.txt', header=True, index=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# dff_filtered_PV = df_busPV_mod[(df_busPV_mod['IndiceInf']>0.20)].sort_values(by=['Gen_Type'])\n","# df_counted = dff_filtered_PV[['BUS_ID', 'BUS_NAME']].value_counts().reset_index()\n","# df = df_counted\n","# num_rows = ((len(df) + 29) // 30)//2\n","# num_columns = 2\n","\n","# if len(df)>30:\n","#     fig, axes = plt.subplots(num_rows, num_columns, figsize=(15, 6 * num_rows), sharex=False)\n","#     axes = axes.flatten()\n","#     # Iterate over subplots and plot each segment\n","#     for i, ax in enumerate(axes):\n","#         start_idx = i * 30\n","#         end_idx = min((i + 1) * 30, len(df))\n","        \n","#         # Plot the bar chart for the current segment\n","#         df_segment = df.iloc[start_idx:end_idx]\n","#         ax.bar(df_segment['BUS_NAME'], df_segment[0])\n","        \n","#         # Set labels and title\n","#         ax.set_ylabel('Occurrences', fontsize=12)\n","#         ax.set_title(f'Segment {i + 1}')\n","#         ax.set_xticklabels(df_segment['BUS_NAME'], rotation=90, ha='center', fontsize=10)\n","#     # Remove empty subplots\n","#     for i in range(len(df), len(axes)):\n","#         fig.delaxes(axes[i])\n","\n","#     # Adjust layout for better appearance\n","#     fig.suptitle('Critical Buses = ' + str(len(df)) , fontsize=16, y=1)\n","# else:\n","#     fig, ax = plt.subplots(1, 1, figsize=(10, 6 ), sharex=False)\n","#     ax.bar(df['BUS_NAME'], df[0])\n","#     ax.set_ylabel('Occurrences', fontsize=12)\n","#     ax.set_xticklabels(df['BUS_NAME'], rotation=90, ha='center', fontsize=10)\n","\n","# plt.tight_layout()\n","# plt.savefig(cenario+'/Fig_CriticalBuses_all.png')\n","# plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## dff_filtered_PQ = df_busPQ_mod[(df_busPQ_mod['IndiceInf']>0.8)].sort_values(by=['Dia','Hora', 'BUS_ID'], ascending=[True, True, True])\n","## barras = list(dff_filtered_PQ['BUS_ID'].unique()) + list(dff_filtered_PV['BUS_ID'].unique())\n","\n","# nome = path_folder.split('/')[-2]+'_mud_01_'\n","# dff_filtered_PV = df_busPV_mod[(df_busPV_mod['IndiceInf']>0.20)].sort_values(by=['Gen_Type'])\n","# # dff_filtered_PV = DF_Merged02.sort_values(by=['Gen_Type'])\n","# EOL_dff_filtered_PV = dff_filtered_PV[dff_filtered_PV['Gen_Type'] == 'EOL']['BUS_ID'].unique()\n","# barras = list(dff_filtered_PV['BUS_ID'].unique())\n","# veclines = []\n","# for bus in barras:\n","#     barra = str(int(bus))\n","#     if bus in EOL_dff_filtered_PV:\n","#         veclines.append('VOLT    ' + barra+'  1.    0.950   1.100\\n')\n","#     else:\n","#         veclines.append('VOLT    ' + barra+'  1.    0.950   1.100\\n')\n","\n","# path1 = 'C:/Users/david/OneDrive/Documents/FERV_BAIXADOS/OPF SIMULADOS/TENSAO_FPO.opf'\n","# with open(path1, 'r') as file:\n","#     lines = file.readlines()\n","\n","# lines[8:8] = veclines\n","# path2 = 'C:/Users/david/OneDrive/Documents/FERV_BAIXADOS/OPF SIMULADOS/TENSAO_FPO_novo.opf'\n","# with open(path2, 'w') as file:\n","#     list_as_string = ''.join(map(str, lines))\n","#     file.write(list_as_string)\n","\n","#====================================================================================================================================================================================\n","# opfNC = Opf_Simulation(path_folder,nome) # Para gerar as pastas \n","#===================================================================================================================================================================================="]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# from Opf_Simulation_filtrado import *\n","# df = Df_PV_UV[Df_PV_UV['UV condition'] == 'Inseguro'].reset_index()\n","# nome = path_folder.split('/')[-2]+'_mud_GER_'\n","# Opf_Simulation_filt(path_folder,nome, df)"]},{"cell_type":"markdown","metadata":{},"source":["# Analise Indice Violação de Tensão"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if ComputeDPI:\n","    if resumoIndice:\n","        def discriminarIndice2(x):\n","            if x>1:\n","                return 'Inseguro'\n","                # return 3\n","            elif (x<=1) & (x>0):\n","                return 'Alarme'\n","                # return 2\n","            elif x == 0:\n","                return 'Seguro'\n","                # return 1\n","\n","        Df_IndiceT2 = pd.concat([dfPQ_CSI[['CSI_SUP_FINAL','CSI_INF_FINAL']],dfPV_CSI[['CSI_SUP_FINAL','CSI_INF_FINAL']]], axis=0, keys=['DPI_PQ', 'DPI_PV'])\n","        Df_IndiceT2['OV condition'] = Df_IndiceT2['CSI_SUP_FINAL'].apply(lambda x: discriminarIndice2(x))\n","        Df_IndiceT2['UV condition'] = Df_IndiceT2['CSI_INF_FINAL'].apply(lambda x: discriminarIndice2(x))\n","        Df_IndiceT2.rename(columns={'CSI_SUP_FINAL':'OV DPI','CSI_INF_FINAL':'UV DPI'}, inplace=True)\n","\n","        # dataNE_1 = Df_IndiceT2.loc[:,:,:,'Nordeste']\n","        # dataN_1 = Df_IndiceT2.loc[:,:,:,'Norte']\n","        # dataSECO_1 = Df_IndiceT2.loc[:,:,:,'Sudeste-Centro-Oeste']\n","        # dataACRO_1 = Df_IndiceT2.loc[:,:,:,'AC-RO']\n","        # dataSul_1 = Df_IndiceT2.loc[:,:,:,'Sul']\n","\n","        Df_seguros_PQ = Df_IndiceT2.loc['DPI_PQ'][((Df_IndiceT2.loc['DPI_PQ']['OV DPI']==0) & (Df_IndiceT2.loc['DPI_PQ']['UV DPI']==0))][['OV condition', 'OV DPI']]\n","        Df_seguros_PV = Df_IndiceT2.loc['DPI_PV'][((Df_IndiceT2.loc['DPI_PV']['OV DPI']==0) & (Df_IndiceT2.loc['DPI_PV']['UV DPI']==0))][['OV condition', 'OV DPI']]\n","        Df_PQ_OV = Df_IndiceT2.loc['DPI_PQ'][~((Df_IndiceT2.loc['DPI_PQ']['OV DPI']==0) & (Df_IndiceT2.loc['DPI_PQ']['UV DPI']>0))].sort_values('OV DPI', ascending=False)[['OV condition', 'OV DPI']]\n","        Df_PQ_UV = Df_IndiceT2.loc['DPI_PQ'][~((Df_IndiceT2.loc['DPI_PQ']['UV DPI']==0) & (Df_IndiceT2.loc['DPI_PQ']['OV DPI']>0))].sort_values('UV DPI', ascending=False)[['UV condition', 'UV DPI']]\n","        Df_PV_OV = Df_IndiceT2.loc['DPI_PV'][~((Df_IndiceT2.loc['DPI_PV']['OV DPI']==0) & (Df_IndiceT2.loc['DPI_PV']['UV DPI']>0))].sort_values('OV DPI', ascending=False)[['OV condition', 'OV DPI']]\n","        Df_PV_UV = Df_IndiceT2.loc['DPI_PV'][~((Df_IndiceT2.loc['DPI_PV']['UV DPI']==0) & (Df_IndiceT2.loc['DPI_PV']['OV DPI']>0))].sort_values('UV DPI', ascending=False)[['UV condition', 'UV DPI']]\n","        Df_IndiceT2.to_csv(cenario+'/Indice.csv')\n","        Df_PV_OV.to_csv(cenario+'/IndicePV_OV.csv')\n","        Df_PV_UV.to_csv(cenario+'/IndicePV_UV.csv')\n","        Df_PQ_OV.to_csv(cenario+'/IndicePQ_OV.csv')\n","        Df_PQ_UV.to_csv(cenario+'/IndicePQ_UV.csv')\n","\n","        path_script_org = cenario + \"/RelatorioIndice.txt\"\n","        numeroPO = len(set(Df_IndiceT2.index.to_frame()[['Dia','Hora']].apply(tuple, axis=1).values))\n","        with open(path_script_org, 'w') as f:\n","            f.write('O numero de pontos de operação analisados são: ' + str(numeroPO) + '\\n')\n","            f.write('=============================\\n Informação Barras PQ:\\n=============================\\n')\n","            regions = Df_PQ_OV.reset_index('REG')['REG'].unique()\n","            for reg in regions:\n","                f.write('- Sobretensão ' + reg +'\\n')\n","                df_reg_sob= Df_PQ_OV.loc[:,:,reg]\n","                f.write('numero de casos Inseguros: '+ str(df_reg_sob[df_reg_sob['OV condition']=='Inseguro'].shape[0])+'\\n')\n","                f.write('numero de casos Alarme: '+ str(df_reg_sob[df_reg_sob['OV condition']=='Alarme'].shape[0])+'\\n')\n","                f.write('numero de casos Seguros: '+ str(df_reg_sob[df_reg_sob['OV condition']=='Seguro'].shape[0])+'\\n')\n","                f.write('- Subtensão '+ reg +'\\n')\n","                df_reg_sub = Df_PQ_UV.loc[:,:,reg]\n","                f.write('numero de casos Inseguros: ' + str(df_reg_sub[df_reg_sub['UV condition']=='Inseguro'].shape[0])+'\\n')\n","                f.write('numero de casos Alarme: ' + str(df_reg_sub[df_reg_sub['UV condition']=='Alarme'].shape[0])+'\\n')\n","                f.write('numero de casos Seguros: ' + str(df_reg_sub[df_reg_sub['UV condition']=='Seguro'].shape[0])+'\\n')\n","                f.write('--------------------------\\n')\n","            f.write('=============================\\n Informação Barras PV:\\n=============================\\n')\n","            for reg in regions:\n","                f.write('- Sobretensão ' + reg +'\\n')\n","                df_reg_sob= Df_PV_OV.loc[:,:,reg]\n","                f.write('numero de casos Inseguros: '+ str(df_reg_sob[df_reg_sob['OV condition']=='Inseguro'].shape[0])+'\\n')\n","                f.write('numero de casos Alarme: '+ str(df_reg_sob[df_reg_sob['OV condition']=='Alarme'].shape[0])+'\\n')\n","                f.write('numero de casos Seguros: '+ str(df_reg_sob[df_reg_sob['OV condition']=='Seguro'].shape[0])+'\\n')\n","                f.write('- Subtensão '+ reg +'\\n')\n","                df_reg_sub = Df_PV_UV.loc[:,:,reg]\n","                f.write('numero de casos Inseguros: ' + str(df_reg_sub[df_reg_sub['UV condition']=='Inseguro'].shape[0])+'\\n')\n","                f.write('numero de casos Alarme: ' + str(df_reg_sub[df_reg_sub['UV condition']=='Alarme'].shape[0])+'\\n')\n","                f.write('numero de casos Seguros: ' + str(df_reg_sub[df_reg_sub['UV condition']=='Seguro'].shape[0])+'\\n')\n","                f.write('--------------------------\\n')"]},{"cell_type":"markdown","metadata":{},"source":["### a) ANALISE CORRELAÇÃO"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# if CorrelationAnalise:\n","#     concatenated_HVDC = pd.concat([df_HVDC.loc['Elo_FOZ-IBIUNA'][' P(MW)'], df_HVDC.loc['Elo_PVEL-ARARQ'][' P(MW)'], df_HVDC.loc['Elo_XINGU-SE'][' P(MW)']], axis=1,keys=['Elo_FOZ-IBIUNA', 'Elo_PVEL-ARARQ', 'Elo_XINGU-SE'])\n","#     concatenated_FluxoAC = pd.concat([DF_Intercambios.loc['Fluxo_N-S']['MW:From-To'],DF_Intercambios.loc['Fluxo_NE-N']['MW:From-To'], DF_Intercambios.loc['Fluxo_NE-SE']['MW:From-To'], DF_Intercambios.loc['Fluxo_SUL-SECO']['MW:From-To']], axis=1, keys=['Fluxo_N-S', 'Fluxo_NE-N', 'Fluxo_NE-SE', 'Fluxo_SUL-SECO'])\n","#     def merge_datapairplot(DF_Intercambios2,DF_REGIONAL_GER,df_HVDC_2, region, col_intercambios_AC):\n","        \n","#         merged_df1 = DF_Intercambios2[col_intercambios_AC].merge(DF_REGIONAL_GER.loc[:, :, region][['PG_MW','QG_MVAR', 'PG/PL', 'QG/QL', 'PG_FERV', 'QG_EOL']], on=['Dia', 'Hora'])\n","#         final_merged_df = merged_df1.merge(df_HVDC_2, on=['Dia', 'Hora'])\n","\n","#         return final_merged_df\n","\n","#     Df__SECO = merge_datapairplot(concatenated_FluxoAC, DF_REGIONAL_GER, concatenated_HVDC, 'Sudeste-Centro-Oeste',['Fluxo_N-S', 'Fluxo_NE-SE', 'Fluxo_SUL-SECO'])\n","#     Df__N = merge_datapairplot(concatenated_FluxoAC, DF_REGIONAL_GER, concatenated_HVDC['Elo_XINGU-SE'], 'Norte',['Fluxo_N-S', 'Fluxo_NE-N'])\n","#     Df__NE = merge_datapairplot( concatenated_FluxoAC,DF_REGIONAL_GER, concatenated_HVDC['Elo_XINGU-SE'], 'Nordeste',['Fluxo_NE-N', 'Fluxo_NE-SE'])\n","#     Df__SUL = merge_datapairplot(concatenated_FluxoAC, DF_REGIONAL_GER, concatenated_HVDC['Elo_FOZ-IBIUNA'], 'Sul',['Fluxo_SUL-SECO'])\n","#     Df__ACRO = merge_datapairplot(concatenated_FluxoAC, DF_REGIONAL_GER, concatenated_HVDC['Elo_PVEL-ARARQ'], 'AC-RO',['Fluxo_NE-SE','Fluxo_N-S', 'Fluxo_SUL-SECO'])\n","\n","#     dfindices = [Df_PQ_OV,Df_PQ_UV,Df_PV_OV,Df_PV_UV]\n","#     typebus = ['PQ','PQ','PV','PV']\n","#     lista_reg = [Df__SECO,Df__N,Df__NE,Df__SUL,Df__ACRO]\n","#     reg = ['Sudeste-Centro-Oeste','Norte','Nordeste','Sul','AC-RO']\n","#     label_colors = {'Inseguro': sns.color_palette(\"Paired\", 10)[5], 'Seguro': sns.color_palette(\"Paired\", 10)[3],'Alarme': sns.color_palette(\"Paired\", 10)[0], }\n","#     # mpl.rcParams[\"axes.labelsize\"] = 12\n","#     for idx, dfreg in enumerate(lista_reg):\n","#         for idx2, df in enumerate(dfindices):\n","#             label = df.columns[0]\n","#             merged_df = df.loc[:,:,reg[idx]].merge(dfreg, on=['Dia', 'Hora']).sort_values(label)\n","\n","#             for columns in merged_df.columns[1:]:\n","#                 fig, axs = plt.subplots(nrows=1, figsize=(10, 6))\n","#                 sns.histplot(data=merged_df, x=columns, hue=label, palette=label_colors, alpha=0.7, element=\"step\", stat=\"density\", common_norm=False)\n","#                 plt.title(reg[idx] + '-' + typebus[idx2])\n","#                 plt.ylabel(\"Density\", fontsize=15)\n","#                 plt.xlabel(columns.replace('_',' '), fontsize=15)\n","#                 name = str(label +'_' + reg[idx] +'_'+ typebus[idx2] +'_'+ columns).replace('/','-')\n","#                 nome = cenario + '/Analise Histograma/' + name +'.png'\n","#                 plt.savefig(nome)\n","#                 plt.show()\n","                \n","#             # g = sns.PairGrid(merged_df, hue=label, corner=True, palette=label_colors)\n","#             # g.map_diag(sns.histplot, multiple=\"stack\",element=\"step\")\n","#             # g.map_offdiag(plt.scatter)\n","#             # g.add_legend(fontsize= '20')\n","#             # name = str(reg[idx] +' '+ typebus[idx2] +' '+ label).replace('_',' ').replace('-',' ')\n","#             # nome = cenario + '/Analise Correlação/' + name +'.png'\n","#             # plt.savefig(nome)\n","#             # plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### b) Leitura do arquivo Tensão.opf"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # Script para ler o arquivo TENSAO_FPO.opf\n","# # *************************************************************************************\n","# path = 'C:/Users/David/OneDrive/Desktop/opfFolder/TENSAO_FPO.opf'\n","# with open(path, 'r') as file:\n","#     lines = file.readlines()\n","\n","# data = []\n","# # Iterar pelas linhas do arquivo\n","# for i in range(len(lines)):\n","#     if (i>7) & (i<451):\n","#         line = lines[i].strip().split()\n","#         data.append(line)\n","\n","# df = pd.DataFrame(data)\n","# df[1] = df[1].astype(float)\n","\n","# busdf = Df_VF[(Df_VF['Dia'] == '01') & (Df_VF['Hora'] == '00-00')]\n","# dff = busdf[busdf['BUS_ID'].isin(df[1].values)]\n","# display(dff['VBASEKV'].value_counts())\n","# display(dff[dff['Gen_Type'].isin(['PCH', 'BIO'])][['BUS_ID', 'BUS_NAME', 'MODV_PU', 'Gen_Type', 'REG', 'VBASEKV', 'TP', 'BASE_MVA', 'PG_MW', 'QG_MVAR', 'PMAX_MW','PMIN_MW', 'QMX_MVAR', 'QMN_MVAR', 'Ger_Units']])\n","\n","# # Step 3: Identify the values from the second DataFrame for filtering\n","# values_to_exclude = dff[dff['VBASEKV']==500]['BUS_ID'].tolist()\n","# # Step 4: Filter the rows of the first DataFr\n","# df1_filtered = df[df[1].isin(values_to_exclude)]\n","# # Step 5: Save the filtered DataFrame to a new text file\n","# df1_filtered.to_csv('filtered_text_file.txt', sep='\\t', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# dff_filtered_PV = df_busPV_mod[(df_busPV_mod['IndiceInf']>0.8)].sort_values(by=['Dia','Hora', 'BUS_ID'], ascending=[True, True, True])\n","# veclines = []\n","# for bus in dff_filtered_PV['BUS_ID'].unique():\n","#     barra = str(int(bus))\n","#     veclines.append('VOLT    ' + barra+'  1.    0.950  1.052\\n')\n","# # *************************************************************************************\n","# path1 = 'C:/Users/David/OneDrive/Desktop/opfFolder/TENSAO_FPO.opf'\n","# with open(path1, 'r') as file:\n","#     lines = file.readlines()\n","\n","# lines[8:8] = veclines\n","# path2 = 'C:/Users/David/OneDrive/Desktop/opfFolder/TENSAO_FPO_novo.opf'\n","# with open(path2, 'w') as file:\n","#     list_as_string = ''.join(map(str, lines))\n","#     file.write(list_as_string)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNwxivoDtHMvBGsdheb1yjL","name":"","version":""},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"vscode":{"interpreter":{"hash":"6a2a0214d38df7dcc88d60fd0083ce83592ef4b41f72cfba9b9d75b1af5e7e91"}}},"nbformat":4,"nbformat_minor":0}
